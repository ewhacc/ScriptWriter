{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce678eb1",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18263a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/lts/1.8/cu111\n",
      "Requirement already satisfied: torch==1.8.2 in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 1)) (1.8.2+cu111)\n",
      "Requirement already satisfied: torchvision==0.9.2 in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 2)) (0.9.2+cu111)\n",
      "Requirement already satisfied: torchaudio==0.8.2 in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 3)) (0.8.2)\n",
      "Requirement already satisfied: transformers==4.21.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 4)) (4.21.1)\n",
      "Requirement already satisfied: gensim==4.2.0 in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 5)) (4.2.0)\n",
      "Requirement already satisfied: tqdm in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 6)) (4.64.0)\n",
      "Requirement already satisfied: gdown in /home/kotech/venv-torch/lib/python3.8/site-packages (from -r requirements-torch-cu111.txt (line 7)) (4.5.1)\n",
      "Requirement already satisfied: numpy in /home/kotech/venv-torch/lib/python3.8/site-packages (from torch==1.8.2->-r requirements-torch-cu111.txt (line 1)) (1.23.1)\n",
      "Requirement already satisfied: typing-extensions in /home/kotech/venv-torch/lib/python3.8/site-packages (from torch==1.8.2->-r requirements-torch-cu111.txt (line 1)) (4.3.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from torchvision==0.9.2->-r requirements-torch-cu111.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (2022.7.25)\n",
      "Requirement already satisfied: requests in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: filelock in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/kotech/venv-torch/lib/python3.8/site-packages (from transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from gensim==4.2.0->-r requirements-torch-cu111.txt (line 5)) (1.9.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from gensim==4.2.0->-r requirements-torch-cu111.txt (line 5)) (6.0.0)\n",
      "Requirement already satisfied: six in /home/kotech/venv-torch/lib/python3.8/site-packages (from gdown->-r requirements-torch-cu111.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/kotech/venv-torch/lib/python3.8/site-packages (from gdown->-r requirements-torch-cu111.txt (line 7)) (4.11.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/kotech/venv-torch/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/kotech/venv-torch/lib/python3.8/site-packages (from beautifulsoup4->gdown->-r requirements-torch-cu111.txt (line 7)) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kotech/venv-torch/lib/python3.8/site-packages (from requests->transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kotech/venv-torch/lib/python3.8/site-packages (from requests->transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kotech/venv-torch/lib/python3.8/site-packages (from requests->transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/kotech/venv-torch/lib/python3.8/site-packages (from requests->transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/kotech/venv-torch/lib/python3.8/site-packages (from requests->transformers==4.21.1->-r requirements-torch-cu111.txt (line 4)) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "# cuda 11.1\n",
    "!pip install -r requirements-torch-cu111.txt --extra-index-url https://download.pytorch.org/whl/lts/1.8/cu111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dc478",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061a428",
   "metadata": {},
   "source": [
    "## 스토리헬퍼 샘플 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac09f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1iSP_YKFs56d5cRRTEMzfedwRxrx-nXWO\n",
      "To: /home/kotech/workspace/ScriptWriter/data/result_list.json\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13.1M/13.1M [00:03<00:00, 3.49MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/result_list.json'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/uc?id=1iSP_YKFs56d5cRRTEMzfedwRxrx-nXWO'\n",
    "output = 'data/result_list.json'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af38109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/result_list.json') as f:\n",
    "    data_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c880d607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'storyline': '우연히 옆집으로 이사 오게 된 차우와 수리첸',\n",
       " 'script': ['집을 구하는 차우.',\n",
       "  '그러나 수엔 부인은 방이 나갔다는 것을 알린다.',\n",
       "  '수엔 부인은 옆집에도 방이 있다며 한 번 볼 것을 권한다.',\n",
       "  '이사를 하는 차우와 수리첸.',\n",
       "  '그러나 동시에 이사를 해서 짐들이 계속 섞인다.',\n",
       "  '남편은 어디에 있냐고 묻는 수엔 부인.',\n",
       "  '수리첸은 남편이 출장 중이라고 말한다.',\n",
       "  '수리첸에게 책을 건네는 차우']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 데이터 출력\n",
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618293c6",
   "metadata": {},
   "source": [
    "**후처리**\n",
    "1. `\\n`을 제거한다. \"부엌에서 일하게 된 마리오\\n인부들 사이에서 인기만점인 베아트리체\"  \n",
    "   ==> 필요없는 것 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48b59ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378 7 부엌에서 일하게 된 마리오\n",
      "인부들 사이에서 인기만점인 베아트리체\n",
      "\"된 \"\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 비정상적 white character가 없는지 확인\n",
    "for idx, data in enumerate(data_dict):\n",
    "    #data['storyline'] = data['storyline'].replace('\\n', ' ')\n",
    "    for i, context in enumerate(data['script']):\n",
    "        #if '\\n' in context:\n",
    "        if '부엌에서 일하게' in context:\n",
    "            print(idx, i, context)\n",
    "            print('\"%s%s\"'%(context[9],context[10]))\n",
    "            print(context[10] == ' ')\n",
    "        #data['script'][i] = context.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58e2ce",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b08482",
   "metadata": {},
   "source": [
    "### kobigbird pretrained model을 이용한 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb68ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('monologg/kobigbird-bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f651a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='monologg/kobigbird-bert-base', vocab_size=32500, model_max_len=4096, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "\n",
      "['<s>', '</s>', '[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
      "[5, 6, 1, 3, 0, 2, 4]\n",
      "sep_token_id = 3\n",
      "unk_token_id = 1\n"
     ]
    }
   ],
   "source": [
    "# tokenizer 기본 설정 정보 출력\n",
    "print(tokenizer)\n",
    "print()\n",
    "# tokenizer special token정보 출력\n",
    "print(tokenizer.all_special_tokens)\n",
    "print(tokenizer.all_special_ids)\n",
    "print('sep_token_id =', tokenizer.sep_token_id)\n",
    "print('unk_token_id =', tokenizer.unk_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb68b219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우연히 옆집으로 이사 오게 된 차우와 수리첸\n",
      "['우연히', '옆집', '##으로', '이사', '오', '##게', '된', '차우', '##와', '수리', '##첸']\n",
      "{'input_ids': [2, 12281, 23393, 9627, 7384, 3649, 4696, 2936, 27898, 4756, 9869, 5810, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "우연히 옆집으로 이사 오게 된 차우와 수리첸\n",
      "[CLS] 우연히 옆집으로 이사 오게 된 차우와 수리첸 [SEP]\n",
      "\n",
      "우연히 옆집으로 이사 오게 된 차우와 수리첸\n",
      "\n",
      "PreTrainedTokenizerFast(name_or_path='monologg/kobigbird-bert-base', vocab_size=32500, model_max_len=4096, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n",
      "['[SEP]']\n"
     ]
    }
   ],
   "source": [
    "s = data_dict[0]['storyline']\n",
    "print(s)\n",
    "tokens = tokenizer.tokenize(s)\n",
    "print(tokens)\n",
    "encoded = tokenizer(s)\n",
    "print(encoded)\n",
    "print()\n",
    "output = tokenizer.convert_tokens_to_string(tokens)\n",
    "print(output)\n",
    "decoded = tokenizer.decode(encoded['input_ids'])\n",
    "print(decoded)\n",
    "print()\n",
    "\n",
    "# [CLS]와 [SEP]은 필요없으므로....\n",
    "encoded = tokenizer(s, add_special_tokens=False)\n",
    "decoded = tokenizer.decode(encoded['input_ids'])\n",
    "print(decoded)\n",
    "print()\n",
    "\n",
    "# [SEP] token을 ScriptWriter모델의 EOS로 사용하자\n",
    "print(tokenizer)\n",
    "print(tokenizer.tokenize('[SEP]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016325f",
   "metadata": {},
   "source": [
    "# source code 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f4b9a4",
   "metadata": {},
   "source": [
    "### 학습 및 검증, 테스트 데이터 셋 생성\n",
    "\n",
    "```py\n",
    "def generate_data_with_random_samples():\n",
    "    # generate negative samples randomly\n",
    "    # In training set, for each sample, we randomly sample a response as a negative candidate\n",
    "    # In development and test set, for each sample, we randomly sample 9 responses as negative candidates and we add a \"EOS\" response as a candidate to let model select when to stop\n",
    "```\n",
    "무작위로 negative sample을 생성한다.  \n",
    "학습set에서는 한개의 무작위 sample을 negative 후보로서 생성한다.\n",
    "```py\n",
    "        for context_id, narrative_id, _ in train:\n",
    "            num_context = len(context_id)\n",
    "            for i in range(1, num_context):\n",
    "                context = context_id[:i]\n",
    "                response = context_id[i]\n",
    "                train_all.append([context, response, narrative_id, 1])\n",
    "                flag = True\n",
    "                while flag:\n",
    "                    # 무작위로 스토리 중의 하나를 고르고, 그 중 무작위 script를 골라서 negative 샘플을 생성한다.\n",
    "                    random_idx = random.randint(0, len(positive_data) - 1)\n",
    "                    random_context = positive_data[random_idx][0]\n",
    "                    random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "                    random_response = random_context[random_idx_2]\n",
    "                    # 만일 정답 response와 추출한 response의 길이가 다르다면 negative 샘플로 추가한다.\n",
    "                    if len(response) != len(random_response):\n",
    "                        flag = False\n",
    "                        train_all.append([context, random_response, narrative_id, 0])\n",
    "                    # 길이가 같다면, 내용을 비교해서 다르다면 negative 샘플로 추가한다. \n",
    "                    else:\n",
    "                        for idx, wid in enumerate(response):\n",
    "                            if wid != random_response[idx]:\n",
    "                                flag = False\n",
    "                                train_all.append([context, random_response, narrative_id, 0])\n",
    "                                break\n",
    "```\n",
    "검증set에서는 9개의 negative sample을 추가한다.  \n",
    "response가 EOS인 경우(마지막인 경우), EOS를 True로 추가한다. (중복???)  \n",
    "그렇지 않을 경우, EOS response를 negative(False)로 추가한다.  \n",
    "테스트set도 동일하다.  \n",
    "```py\n",
    "        for context_id, narrative_id, _ in dev:\n",
    "            num_context = len(context_id)\n",
    "            for i in range(1, num_context):\n",
    "                context = context_id[:i]\n",
    "                response = context_id[i]\n",
    "                dev_all.append([context, response, narrative_id, 1])\n",
    "                count = 0\n",
    "                negative_samples = []\n",
    "                # total count = 1(positive) + 8(negative) + 1(EOS) 가 되어야함.\n",
    "                # 아래의 count는 count < 8로 수정 필요\n",
    "                while count < 9:\n",
    "                    random_idx = random.randint(0, len(positive_data) - 1)\n",
    "                    random_context = positive_data[random_idx][0]\n",
    "                    random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "                    random_response = random_context[random_idx_2]\n",
    "                    if random_response not in negative_samples and random_response != [EOS_ID]:\n",
    "                        if len(response) != len(random_response):\n",
    "                            dev_all.append([context, random_response, narrative_id, 0])\n",
    "                            count += 1\n",
    "                            negative_samples.append(random_response)\n",
    "                        else:\n",
    "                            for idx, wid in enumerate(response):\n",
    "                                if wid != random_response[idx]:\n",
    "                                    dev_all.append([context, random_response, narrative_id, 0])\n",
    "                                    count += 1\n",
    "                                    negative_samples.append(random_response)\n",
    "                                    break\n",
    "                if response == [EOS_ID]:\n",
    "                    dev_all.append([context, [EOS_ID], narrative_id, 1])\n",
    "                else:\n",
    "                    dev_all.append([context, [EOS_ID], narrative_id, 0])\n",
    "```\n",
    "**To-Do**   \n",
    "Solr sample 추가가 필요한가?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0d332",
   "metadata": {},
   "source": [
    "### pickle data 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6669fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/train.gr.pkl', 'rb') as f:\n",
    "    train_gr = pickle.load(f)\n",
    "    \n",
    "with open('data/dev.gr.pkl', 'rb') as f:\n",
    "    dev_gr = pickle.load(f)\n",
    "    \n",
    "with open('data/test.gr.pkl', 'rb') as f:\n",
    "    test_gr = pickle.load(f)\n",
    "    \n",
    "with open('data/embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b765aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data tuple size = 5\n",
      "utterance shape = (136524, 11, 50)\n",
      "response shape = (136524, 50)\n",
      "narrative shape = (136524, 50)\n",
      "gt_response shape = (136524, 50)\n",
      "y_true shape = (136524,)\n"
     ]
    }
   ],
   "source": [
    "print('train data tuple size =', len(train_gr))\n",
    "print('utterance shape =', train_gr[0].shape)\n",
    "print('response shape =', train_gr[1].shape)\n",
    "print('narrative shape =', train_gr[2].shape)\n",
    "print('gt_response shape =', train_gr[3].shape)\n",
    "print('y_true shape =', train_gr[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0dc8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_number = len(train_gr[4])\n",
    "val_number = len(dev_gr[4])\n",
    "test_number = len(test_gr[4])\n",
    "#total_number_of_data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "560949af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136524, 37480, 38320)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original dataset numbers\n",
    "train_number, val_number, test_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8051cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance cnt = 1\n",
      "resonse = [   5  164   48    4 5334  123 2778    3    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "narrative = [10958 13504   137     8  2778     4     3    11    29   267     8     9\n",
      "    11 10915   867  3205     1    46   101   111  4745 23556   867     3\n",
      "   173    29    99  2373  2523    51     2    64     3     8    47    51\n",
      "    72  5339 16837     2     1   104  4531    27     2   363    15   117\n",
      "    71  5440]\n",
      "gt_response = [   5  164   48    4 5334  123 2778    3    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "y_true = 1\n"
     ]
    }
   ],
   "source": [
    "def get_data(data, idx):\n",
    "    return data[0][idx], data[1][idx], data[2][idx], data[3][idx], data[4][idx]\n",
    "\n",
    "def sample_data_print(utterance, response, narrative, gt_response, y_true):\n",
    "    #print('1st script =', utterance[0])\n",
    "    #print('2nd script =', utterance[1])\n",
    "    for i, utt in enumerate(utterance):\n",
    "        if (utt == [0]*50).all():\n",
    "            break\n",
    "    print('utterance cnt =', i)\n",
    "    print('resonse =', response)\n",
    "    print('narrative =', narrative)\n",
    "    print('gt_response =', gt_response)\n",
    "    print('y_true =', y_true)\n",
    "\n",
    "def browse_idx(data, idx):\n",
    "    utterance, response, narrative, gt_response, y_true = get_data(data, idx)\n",
    "    sample_data_print(utterance, response, narrative, gt_response, y_true)\n",
    "\n",
    "def get_utterance_len(data, idx):\n",
    "    utterance, response, narrative, gt_response, y_true = get_data(data, idx)\n",
    "    for i, utt in enumerate(utterance):\n",
    "        if (utt == [0]*50).all():\n",
    "            break\n",
    "    return i\n",
    "\n",
    "browse_idx(train_gr, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd2e816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance cnt = 1\n",
      "resonse = [   5   73   31   57  130    9 4446    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "narrative = [10958 13504   137     8  2778     4     3    11    29   267     8     9\n",
      "    11 10915   867  3205     1    46   101   111  4745 23556   867     3\n",
      "   173    29    99  2373  2523    51     2    64     3     8    47    51\n",
      "    72  5339 16837     2     1   104  4531    27     2   363    15   117\n",
      "    71  5440]\n",
      "gt_response = [   5  164   48    4 5334  123 2778    3    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "y_true = 0\n"
     ]
    }
   ],
   "source": [
    "# negative sample\n",
    "browse_idx(train_gr, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c57cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance cnt = 2\n",
      "resonse = [267  77  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "narrative = [10958 13504   137     8  2778     4     3    11    29   267     8     9\n",
      "    11 10915   867  3205     1    46   101   111  4745 23556   867     3\n",
      "   173    29    99  2373  2523    51     2    64     3     8    47    51\n",
      "    72  5339 16837     2     1   104  4531    27     2   363    15   117\n",
      "    71  5440]\n",
      "gt_response = [267  77  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "y_true = 1\n"
     ]
    }
   ],
   "source": [
    "# 2nd sample with two utterance\n",
    "browse_idx(train_gr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e01ffeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance cnt = 8\n",
      "resonse = [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "narrative = [10958 13504   137     8  2778     4     3    11    29   267     8     9\n",
      "    11 10915   867  3205     1    46   101   111  4745 23556   867     3\n",
      "   173    29    99  2373  2523    51     2    64     3     8    47    51\n",
      "    72  5339 16837     2     1   104  4531    27     2   363    15   117\n",
      "    71  5440]\n",
      "gt_response = [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_true = 1\n"
     ]
    }
   ],
   "source": [
    "# last script\n",
    "browse_idx(train_gr, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987734e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gr[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79fa973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "2 2\n",
      "4 3\n",
      "6 4\n",
      "8 5\n",
      "10 6\n",
      "12 7\n",
      "14 8\n",
      "120 9\n",
      "314 10\n"
     ]
    }
   ],
   "source": [
    "# check utterance len\n",
    "max_utt_len = 0\n",
    "for i in range(train_gr[0].shape[0]):\n",
    "    utt_len = get_utterance_len(train_gr, i)\n",
    "    if utt_len > max_utt_len:\n",
    "        max_utt_len = utt_len\n",
    "        print(i, max_utt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beadbfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "10 2\n",
      "50 3\n",
      "60 4\n",
      "110 5\n",
      "470 6\n",
      "480 7\n",
      "760 8\n",
      "850 9\n",
      "1300 10\n"
     ]
    }
   ],
   "source": [
    "# check utterance len\n",
    "max_utt_len = 0\n",
    "for i in range(dev_gr[0].shape[0]):\n",
    "    utt_len = get_utterance_len(dev_gr, i)\n",
    "    if utt_len > max_utt_len:\n",
    "        max_utt_len = utt_len\n",
    "        print(i, max_utt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6771e8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  486,    32,    73,  9178,     5,     2, 11099,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [  913, 15855,     2,   128,   105,   169,    37,  7022,     2,\n",
       "         4885,  9643,     2,  2914,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최대 10개의 utterance가 있다. 11번째는 항상 [0.]*50이고, [EOS_ID]는 없을 수도 있다.\n",
    "utterance, response, narrative, gt_response, y_true = get_data(dev_gr, 1300)\n",
    "utterance[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81633020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1758,  7785,   183,    15,    11,  1060,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [ 1856,     1,     6,    33,  2433, 11766,     2,  3945,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최대 10개의 utterance가 있다. 11번째는 항상 [0.]*50이고, [EOS_ID]는 없을 수도 있다.\n",
    "utterance, response, narrative, gt_response, y_true = get_data(train_gr, 314)\n",
    "utterance[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3524a7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1758, 7785,  183,   15,   11, 1060,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utterance, response, narrative, gt_response, y_true = get_data(train_gr, 312)\n",
    "utterance[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a8c1f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance cnt = 2\n",
      "resonse = [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "narrative = [7234 1152   26  686   56    4    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "gt_response = [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_true = 1\n",
      "\n",
      "utterance cnt = 2\n",
      "resonse = [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "narrative = [7234 1152   26  686   56    4    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "gt_response = [7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_true = 1\n"
     ]
    }
   ],
   "source": [
    "# 정답이 EOS인 경우 10번째 뒤에 중복적으로 데이터 들어 있음\n",
    "browse_idx(dev_gr, 10)\n",
    "print()\n",
    "browse_idx(dev_gr, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "37dea0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utterance cnt = 2\n",
      "resonse = [ 486  229   28    6  168  545    8 1113    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "narrative = [ 126   13  212   19  536    3  754  123 1073  893    3  364    9   20\n",
      "   11    1 7838  599  676   38   28    2 1476  521    3 3133   47   20\n",
      "   11    1  526    2  210  126    6 1162   23   72   89  103   11    1\n",
      "    0    0    0    0    0    0    0    0]\n",
      "gt_response = [ 486  229   28    6  168  545    8 1113    1    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "y_true = 1\n"
     ]
    }
   ],
   "source": [
    "browse_idx(dev_pad, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d3d2b750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43514, 200)\n"
     ]
    }
   ],
   "source": [
    "# shape of embeddings (총단어수+1=43514, embedding_size=203)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "797f20b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddings의 첫번째 data는 0.으로 채워져 있다. PADDING용 이다.\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab61f27",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e81a5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all suitable sessions:  11655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "EOS_ID = tokenizer.sep_token_id\n",
    "\n",
    "positive_sessions = []\n",
    "for unit_data in data_dict:\n",
    "    unit_contexts = [tokenizer.tokenize(text) for text in unit_data['script'] + ['[SEP]'] ]\n",
    "    unit_narrative = tokenizer.tokenize(unit_data['storyline'])\n",
    "    positive_sessions.append([unit_contexts, unit_narrative, 1])\n",
    "print(\"all suitable sessions: \", len(positive_sessions))\n",
    "\n",
    "# reproducibility를 위한 random seed 설정\n",
    "np.random.seed(42)\n",
    "# random shuffle data\n",
    "np.random.shuffle(positive_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc46677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train = 10489 , val = 582 , test = 584\n"
     ]
    }
   ],
   "source": [
    "train_num = int(len(positive_sessions) * 0.9)\n",
    "dev_test_num = int(len(positive_sessions) * 0.05)\n",
    "train_sessions, dev_sessions, test_sessions = positive_sessions[:train_num], positive_sessions[train_num: train_num + dev_test_num], positive_sessions[train_num + dev_test_num:]\n",
    "print('number of train =', len(train_sessions), ', val =', len(dev_sessions), ', test =', len(test_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "132fe371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word2vec training sentences = 144229\n"
     ]
    }
   ],
   "source": [
    "train_texts = []\n",
    "for train_session in train_sessions:\n",
    "    train_texts += train_session[0]\n",
    "    train_texts.append(train_session[1])\n",
    "print('number of word2vec training sentences =', len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c59077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['불안',\n",
       "   '##해',\n",
       "   '하',\n",
       "   '##는',\n",
       "   '미치',\n",
       "   '가족',\n",
       "   '##들',\n",
       "   ',',\n",
       "   '멜라',\n",
       "   '##니',\n",
       "   '##가',\n",
       "   '앨리스',\n",
       "   '##를',\n",
       "   '다독',\n",
       "   '##인다',\n",
       "   '.'],\n",
       "  ['창문',\n",
       "   '##을',\n",
       "   '확인',\n",
       "   '##하',\n",
       "   '##는',\n",
       "   '미치',\n",
       "   '멜라',\n",
       "   '##니',\n",
       "   '##가',\n",
       "   '사',\n",
       "   '##온',\n",
       "   '잉',\n",
       "   '##꼬',\n",
       "   '##를',\n",
       "   '보고',\n",
       "   '착',\n",
       "   '##잡',\n",
       "   '##해',\n",
       "   '##한다',\n",
       "   '.'],\n",
       "  ['불안', '##해', '하', '##는', '미치', '가족', '##과', '멜라', '##니', '.'],\n",
       "  ['드디어', '새', '##들', '##의', '공격', '##이', '시작', '##된', '##다', '.'],\n",
       "  ['팔',\n",
       "   '##의',\n",
       "   '상처',\n",
       "   '##를',\n",
       "   '입',\n",
       "   '##은',\n",
       "   '미치',\n",
       "   '##가',\n",
       "   '새',\n",
       "   '##들',\n",
       "   '##의',\n",
       "   '공격',\n",
       "   '##을',\n",
       "   '맨',\n",
       "   '##손',\n",
       "   '##으로',\n",
       "   '막아내',\n",
       "   '##지만',\n",
       "   '역부족',\n",
       "   '##이다',\n",
       "   '.'],\n",
       "  ['새',\n",
       "   '##들이',\n",
       "   '떠나',\n",
       "   '##고',\n",
       "   '조용',\n",
       "   '##해',\n",
       "   '##지',\n",
       "   '##자',\n",
       "   '한',\n",
       "   '숨',\n",
       "   '돌리',\n",
       "   '##는',\n",
       "   '사람',\n",
       "   '##들',\n",
       "   '.'],\n",
       "  ['[SEP]']],\n",
       " ['불안', '##해하', '##는', '멜라', '##니', '##와', '미치', '가족', '.'],\n",
       " 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sessions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41b03ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['새',\n",
       "  '##들이',\n",
       "  '떠나',\n",
       "  '##고',\n",
       "  '조용',\n",
       "  '##해',\n",
       "  '##지',\n",
       "  '##자',\n",
       "  '한',\n",
       "  '숨',\n",
       "  '돌리',\n",
       "  '##는',\n",
       "  '사람',\n",
       "  '##들',\n",
       "  '.'],\n",
       " ['[SEP]'],\n",
       " ['불안', '##해하', '##는', '멜라', '##니', '##와', '미치', '가족', '.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7540667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# word2vec 학습\n",
    "model = Word2Vec(sentences = train_texts, vector_size = 200, window = 7, min_count = 5, workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ecb91",
   "metadata": {},
   "source": [
    "**참조 링크**  \n",
    "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/  \n",
    "https://wikidocs.net/50739  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52e2e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of words = 11882\n",
      "first word = \".\"\n",
      "last word = \"디지털\"\n"
     ]
    }
   ],
   "source": [
    "print('total num of words =', len(model.wv.key_to_index))\n",
    "print('first word = \"%s\"'%model.wv.index_to_key[0])\n",
    "print('last word = \"%s\"'%model.wv.index_to_key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4707535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('친구', 0.7315929532051086), ('동생', 0.6732680797576904), ('친척', 0.6680057048797607), ('팀원', 0.6401212215423584), ('딸', 0.6389485597610474), ('동료', 0.6264671087265015), ('아들', 0.6261126399040222), ('식구', 0.6248003840446472), ('아이', 0.6204746961593628), ('동물', 0.6170737147331238)]\n"
     ]
    }
   ],
   "source": [
    "# word2vec이 잘 학습되었는지 여러가지 테스트를 수행하자.\n",
    "print(model.wv.most_similar(\"가족\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d73cfc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "[-0.76283157  0.7367452   0.7323906   0.58017033  1.6211158 ]\n",
      "753\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "key = '가족'\n",
    "print(model.wv.key_to_index[key])\n",
    "print(model.wv.get_vector(key)[:5])\n",
    "key = '[UNK]'\n",
    "print(model.wv.key_to_index[key])\n",
    "print(model.wv.key_to_index.get('최민수', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "076381d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6140388  -0.16637625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.6140388 , -0.16637625], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.wv.get_vector(0)[:2])\n",
    "model.wv.get_vector('.')[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ad5d7",
   "metadata": {},
   "source": [
    "## 데이터 저장\n",
    "\n",
    "`embeddings.pkl`과 `vocab.txt`를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8453ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/vocab.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for i, key in enumerate(model.wv.index_to_key):\n",
    "        file.write('%s\\t%i\\n'%(key, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67a3bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "new_embeddings = np.array([[0.]*200],dtype='float32') \n",
    "for i in range(len(model.wv.index_to_key)):\n",
    "    new_embeddings = np.append(new_embeddings, [model.wv.get_vector(i)], axis=0)\n",
    "\n",
    "with open('data/embeddings_ko.pkl', 'wb') as f:\n",
    "    pickle.dump(new_embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4ec99",
   "metadata": {},
   "source": [
    "# 학습 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "066fc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_ID = model.wv.key_to_index['[SEP]']+1\n",
    "UNK_ID = model.wv.key_to_index['[UNK]']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a86226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vocab = {}\n",
    "positive_data = []\n",
    "\n",
    "with open(\"./data/vocab.txt\", \"r\", encoding=\"utf-8\") as fr:\n",
    "    for idx, line in enumerate(fr):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        vocab[line[0]] = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0501f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample id 출력 확인\n",
    "vocab['가족']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611b33b",
   "metadata": {},
   "source": [
    "**positive data 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f165912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = []\n",
    "\n",
    "for unit in positive_sessions:\n",
    "    narrative = unit[1]\n",
    "    #print(narrative)\n",
    "    context = unit[0]\n",
    "    narrative_id = [vocab.get(word, UNK_ID) for word in narrative]\n",
    "    context_id = [[vocab.get(word, UNK_ID) for word in sent] for sent in context]\n",
    "    if len(narrative_id) == 0 or len(context_id) == 0:\n",
    "        continue\n",
    "    data = [context_id, narrative_id, 1]\n",
    "    positive_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9944ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_test_num = int(len(positive_data) * 0.05)\n",
    "train, dev, test = positive_data[:train_num], positive_data[train_num: train_num + dev_test_num], positive_data[train_num + dev_test_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22242ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1154, 36, 26, 2, 1227, 134, 15, 24, 2119, 60, 10, 462, 4, 5485, 831, 1]], [945, 3, 342, 12, 2, 1227, 2119, 60, 10, 230, 294, 1699, 5439, 4, 77, 3416, 2321, 36, 14, 1], [1154, 979, 2, 2119, 60, 17, 1227, 134, 1], [945, 3, 342, 12, 2, 1227, 2119, 60, 10, 230, 294, 1699, 5439, 4, 77, 3416, 2321, 36, 14, 1], 1]\n",
      "[[[1154, 36, 26, 2, 1227, 134, 15, 24, 2119, 60, 10, 462, 4, 5485, 831, 1]], [170, 24, 3334, 3, 963, 145, 10, 123, 21, 107, 19, 968, 640, 11, 1], [1154, 979, 2, 2119, 60, 17, 1227, 134, 1], [945, 3, 342, 12, 2, 1227, 2119, 60, 10, 230, 294, 1699, 5439, 4, 77, 3416, 2321, 36, 14, 1], 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_all, dev_all, test_all = [], [], []\n",
    "for context_id, narrative_id, _ in train:\n",
    "    num_context = len(context_id)\n",
    "    for i in range(1, num_context):\n",
    "        context = context_id[:i]\n",
    "        response = context_id[i]\n",
    "        train_all.append([context, response, narrative_id, response, 1])\n",
    "        flag = True\n",
    "        while flag:\n",
    "            random_idx = random.randint(0, len(positive_data) - 1)\n",
    "            random_context = positive_data[random_idx][0]\n",
    "            random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "            random_response = random_context[random_idx_2]\n",
    "            if len(response) != len(random_response):\n",
    "                flag = False\n",
    "                train_all.append([context, random_response, narrative_id, response, 0])\n",
    "            else:\n",
    "                for idx, wid in enumerate(response):\n",
    "                    if wid != random_response[idx]:\n",
    "                        flag = False\n",
    "                        train_all.append([context, random_response, narrative_id, response, 0])\n",
    "                        break\n",
    "print(train_all[0]) \n",
    "print(train_all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "287d8fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[742, 6671, 29, 591, 274, 212, 6, 6655, 8, 147, 1]], [28, 2, 942, 368, 3, 217, 4, 35, 1], [126, 13, 212, 19, 536, 3, 754, 123, 1073, 893, 3, 364, 9, 20, 11, 1, 7838, 599, 676, 38, 28, 2, 1476, 521, 3, 3133, 47, 20, 11, 1, 526, 2, 210, 126, 6, 1162, 23, 72, 89, 103, 11, 1], [28, 2, 942, 368, 3, 217, 4, 35, 1], 1] [[[742, 6671, 29, 591, 274, 212, 6, 6655, 8, 147, 1]], [82, 15, 23, 4309, 4, 163, 2, 1459, 1], [126, 13, 212, 19, 536, 3, 754, 123, 1073, 893, 3, 364, 9, 20, 11, 1, 7838, 599, 676, 38, 28, 2, 1476, 521, 3, 3133, 47, 20, 11, 1, 526, 2, 210, 126, 6, 1162, 23, 72, 89, 103, 11, 1], [28, 2, 942, 368, 3, 217, 4, 35, 1], 0] [[[742, 6671, 29, 591, 274, 212, 6, 6655, 8, 147, 1]], [5200, 9502, 1962, 1886, 1036, 8601, 30, 5, 7, 6255, 7531, 10, 303, 40, 18, 12, 2, 227, 1], [126, 13, 212, 19, 536, 3, 754, 123, 1073, 893, 3, 364, 9, 20, 11, 1, 7838, 599, 676, 38, 28, 2, 1476, 521, 3, 3133, 47, 20, 11, 1, 526, 2, 210, 126, 6, 1162, 23, 72, 89, 103, 11, 1], [28, 2, 942, 368, 3, 217, 4, 35, 1], 0]\n"
     ]
    }
   ],
   "source": [
    "for context_id, narrative_id, _ in dev:\n",
    "    num_context = len(context_id)\n",
    "    for i in range(1, num_context):\n",
    "        context = context_id[:i]\n",
    "        response = context_id[i]\n",
    "        dev_all.append([context, response, narrative_id, response, 1])\n",
    "        count = 0\n",
    "        negative_samples = []\n",
    "        # fix count 버그\n",
    "        while count < 8:\n",
    "            random_idx = random.randint(0, len(positive_data) - 1)\n",
    "            random_context = positive_data[random_idx][0]\n",
    "            random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "            random_response = random_context[random_idx_2]\n",
    "            if random_response not in negative_samples and random_response != [EOS_ID]:\n",
    "                if len(response) != len(random_response):\n",
    "                    dev_all.append([context, random_response, narrative_id, response, 0])\n",
    "                    count += 1\n",
    "                    negative_samples.append(random_response)\n",
    "                else:\n",
    "                    for idx, wid in enumerate(response):\n",
    "                        if wid != random_response[idx]:\n",
    "                            dev_all.append([context, random_response, narrative_id, response, 0])\n",
    "                            count += 1\n",
    "                            negative_samples.append(random_response)\n",
    "                            break\n",
    "        if response == [EOS_ID]:\n",
    "            dev_all.append([context, [EOS_ID], narrative_id, response, 1])\n",
    "        else:\n",
    "            dev_all.append([context, [EOS_ID], narrative_id, response, 0])\n",
    "print(dev_all[0], dev_all[1], dev_all[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d77f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[261, 2, 1410, 5, 7, 32, 6, 286, 3, 727, 14, 1]], [28, 2, 1410, 4, 373, 9, 20, 11, 1], [261, 2, 709, 2266, 23, 961, 8, 1360, 1, 96, 509, 95, 7, 191, 416, 404, 1042, 2, 261, 4, 1528, 36, 250, 1], [28, 2, 1410, 4, 373, 9, 20, 11, 1], 1] [[[261, 2, 1410, 5, 7, 32, 6, 286, 3, 727, 14, 1]], [370, 572, 15, 3, 77, 203, 2, 275, 23, 580], [261, 2, 709, 2266, 23, 961, 8, 1360, 1, 96, 509, 95, 7, 191, 416, 404, 1042, 2, 261, 4, 1528, 36, 250, 1], [28, 2, 1410, 4, 373, 9, 20, 11, 1], 0] [[[261, 2, 1410, 5, 7, 32, 6, 286, 3, 727, 14, 1]], [815, 17, 815, 6, 237, 15, 13, 243, 4, 35, 1], [261, 2, 709, 2266, 23, 961, 8, 1360, 1, 96, 509, 95, 7, 191, 416, 404, 1042, 2, 261, 4, 1528, 36, 250, 1], [28, 2, 1410, 4, 373, 9, 20, 11, 1], 0]\n"
     ]
    }
   ],
   "source": [
    "for context_id, narrative_id, _ in test:\n",
    "    num_context = len(context_id)\n",
    "    for i in range(1, num_context):\n",
    "        context = context_id[:i]\n",
    "        response = context_id[i]\n",
    "        test_all.append([context, response, narrative_id, response, 1])\n",
    "        count = 0\n",
    "        negative_samples = []\n",
    "        # fix count 버그\n",
    "        while count < 8:\n",
    "            random_idx = random.randint(0, len(positive_data) - 1)\n",
    "            random_context = positive_data[random_idx][0]\n",
    "            random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "            random_response = random_context[random_idx_2]\n",
    "            if random_response not in negative_samples and random_response != [EOS_ID]:\n",
    "                if len(response) != len(random_response):\n",
    "                    test_all.append([context, random_response, narrative_id, response, 0])\n",
    "                    negative_samples.append(random_response)\n",
    "                    count += 1\n",
    "                else:\n",
    "                    for idx, id in enumerate(response):\n",
    "                        if id != random_response[idx]:\n",
    "                            test_all.append([context, random_response, narrative_id, response, 0])\n",
    "                            negative_samples.append(random_response)\n",
    "                            count += 1\n",
    "                            break\n",
    "        if response == [EOS_ID]:\n",
    "            test_all.append([context, [EOS_ID], narrative_id, response, 1])\n",
    "        else:\n",
    "            test_all.append([context, [EOS_ID], narrative_id, response, 0])\n",
    "print(test_all[0], test_all[1], test_all[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5c5b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train count = 246578\n",
      "total val count = 66430\n",
      "total test count = 66830\n"
     ]
    }
   ],
   "source": [
    "print('total train count =', len(train_all))\n",
    "print('total val count =', len(dev_all))\n",
    "print('total test count =', len(test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47cd19f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0, 0, 0],\n",
       "       [4, 5, 6, 0, 0],\n",
       "       [7, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_numpy_from_nonfixed_2d_array(aa, max_sentence_len=50, max_num_utterance=10, padding_value=0):\n",
    "    PAD_SEQUENCE = np.array([0] * max_sentence_len)\n",
    "    rows = np.empty([0, max_sentence_len], dtype='int')\n",
    "    aa = aa[:max_num_utterance]\n",
    "    for a in aa:\n",
    "        sentence_len = len(a)\n",
    "        if sentence_len < max_sentence_len:\n",
    "            rows  = np.append(rows, [np.pad(a, (0, max_sentence_len-sentence_len), 'constant', constant_values=padding_value)[:max_sentence_len]], axis=0)\n",
    "        else:\n",
    "            rows = np.append(rows, [a[:max_sentence_len]], axis=0)\n",
    "    num_utterance = len(aa)\n",
    "    if num_utterance < max_num_utterance:\n",
    "        rows = np.append(rows, [PAD_SEQUENCE]*(max_num_utterance-num_utterance), axis=0)\n",
    "    # add empty +1 sentence\n",
    "    rows = np.append(rows, [PAD_SEQUENCE], axis=0)\n",
    "    #return np.concatenate(rows, axis=0).reshape(-1, max_sentence_len)\n",
    "    return rows\n",
    "\n",
    "def get_numpy_from_nonfixed_1d_array(a, max_sentence_len=50, padding_value=0):\n",
    "    sentence_len = len(a)\n",
    "    if sentence_len < max_sentence_len:\n",
    "        return np.pad(a, (0, max_sentence_len-sentence_len), 'constant', constant_values=padding_value)\n",
    "    else:\n",
    "        return np.array(a[:max_sentence_len])\n",
    "\n",
    "cc_test_data = [\n",
    "        [1,2],\n",
    "        [4,5,6],\n",
    "        [7]\n",
    "     ]\n",
    "get_numpy_from_nonfixed_2d_array(cc_test_data, max_sentence_len=5, max_num_utterance=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "51302d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numpy_from_nonfixed_1d_array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "475ebe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 246578/246578 [00:43<00:00, 5724.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66430/66430 [00:11<00:00, 5698.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66830/66830 [00:11<00:00, 5590.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def pad_process(data, max_sentence_len=50, max_num_utterance=10):\n",
    "    utterance = []\n",
    "    response = []\n",
    "    narrative = []\n",
    "    gt_response = []\n",
    "    y_true = []\n",
    "    for unit in tqdm(data):\n",
    "        utterance.append(get_numpy_from_nonfixed_2d_array(unit[0]))\n",
    "        response.append(get_numpy_from_nonfixed_1d_array(unit[1]))\n",
    "        narrative.append(get_numpy_from_nonfixed_1d_array(unit[2]))\n",
    "        gt_response.append(get_numpy_from_nonfixed_1d_array(unit[3]))\n",
    "        y_true.append(unit[4])\n",
    "        \n",
    "    utterance = np.stack(utterance)\n",
    "    response = np.stack(response)\n",
    "    narrative = np.stack(narrative)\n",
    "    gt_response = np.stack(gt_response)\n",
    "    y_true = np.stack(y_true)\n",
    "    return (utterance, response, narrative, gt_response, y_true)\n",
    "\n",
    "train_pad = pad_process(train_all)\n",
    "dev_pad = pad_process(dev_all)\n",
    "test_pad = pad_process(test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003946db",
   "metadata": {},
   "source": [
    "**학습데이터셋 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4d8dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_ko.pkl', 'wb') as f:\n",
    "    pickle.dump(train_pad, f)\n",
    "with open('data/dev_ko.pkl', 'wb') as f:\n",
    "    pickle.dump(dev_pad, f)\n",
    "with open('data/test_ko.pkl', 'wb') as f:\n",
    "    pickle.dump(test_pad, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214841c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
