{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce678eb1",
   "metadata": {},
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18263a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 11.1\n",
    "#!pip install -r requirements-torch-cu111.txt --extra-index-url https://download.pytorch.org/whl/lts/1.8/cu111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5aa70c-bcc0-451d-98a5-fe4565370fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list | grep -E \"gdown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a96d89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abdb1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'final'\n",
    "# AI hub 업로드 용 변경\n",
    "#url = 'https://drive.google.com/uc?id=1qQQbjFd0c7unV-S18t-7x3KUw5OFVl3P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db1b4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scripts_file = f'data/json_split.zip'\n",
    "#gdown.download(url, scripts_file, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450a0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!zipu --extract --encoding cp949 'data/json_split.zip' 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40576bed-862b-48ed-a41d-2b0eaa6f20d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469M\tdata/train\n",
      "63M\tdata/validation\n"
     ]
    }
   ],
   "source": [
    "!du -sh data/train\n",
    "!du -sh data/validation\n",
    "#!du -sh data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1255e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df945932",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = sorted(glob('data/train/*/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a6bcfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3160"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107e0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = []\n",
    "for json_file in json_files:\n",
    "    with open(json_file) as f:\n",
    "        story_dict = json.load(f)\n",
    "    units = story_dict['units']\n",
    "    for unit in units:\n",
    "        unit_dict = {}\n",
    "        unit_dict['uid'] = unit['id']\n",
    "        unit_dict['storyline'] = unit['storyline']\n",
    "        unit_dict['script'] = []\n",
    "        for story_script in unit['story_scripts']:\n",
    "            unit_dict['script'].append(story_script['content'])\n",
    "        data_dict.append(unit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e89c36ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train num = 79782\n"
     ]
    }
   ],
   "source": [
    "train_num = len(data_dict)\n",
    "print('train num =', train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f397b4aa-0757-4d10-b284-43ae87e8ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401\n"
     ]
    }
   ],
   "source": [
    "json_files = sorted(glob('data/validation/*/*.json'))\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9bcaf02-fbc9-455f-9cb2-7376d26580a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_num = 10069\n"
     ]
    }
   ],
   "source": [
    "val_num = 0\n",
    "for json_file in json_files:\n",
    "    with open(json_file) as f:\n",
    "        story_dict = json.load(f)\n",
    "    units = story_dict['units']\n",
    "    for unit in units:\n",
    "        unit_dict = {}\n",
    "        unit_dict['uid'] = unit['id']\n",
    "        unit_dict['storyline'] = unit['storyline']\n",
    "        unit_dict['script'] = []\n",
    "        for story_script in unit['story_scripts']:\n",
    "            unit_dict['script'].append(story_script['content'])\n",
    "        data_dict.append(unit_dict)\n",
    "        val_num += 1\n",
    "print('val_num =', val_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c43c64b-0363-4677-9bb5-a3039dfc76e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n"
     ]
    }
   ],
   "source": [
    "json_files = sorted(glob('data/test/*/*.json'))\n",
    "print(len(json_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ec2831e-7004-4e94-9fc8-8527dee86238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test num = 10226\n"
     ]
    }
   ],
   "source": [
    "test_num = 0\n",
    "for json_file in json_files:\n",
    "    with open(json_file) as f:\n",
    "        story_dict = json.load(f)\n",
    "    units = story_dict['units']\n",
    "    for unit in units:\n",
    "        unit_dict = {}\n",
    "        unit_dict['uid'] = unit['id']\n",
    "        unit_dict['storyline'] = unit['storyline']\n",
    "        unit_dict['script'] = []\n",
    "        for story_script in unit['story_scripts']:\n",
    "            unit_dict['script'].append(story_script['content'])\n",
    "        data_dict.append(unit_dict)\n",
    "        test_num += 1\n",
    "print('test num =', test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a67e5eea-1275-495b-97d5-ec42cbaea9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100077"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dc478",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c1fe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefix = 'final'\n",
    "#url = 'https://drive.google.com/uc?id=1Bts2h-QPQ5-m7sDIXgVRfumjl-8XHOst'\n",
    "#url = 'https://drive.google.com/uc?id=1x6HuyJTQcNydJ9P-fJl2LtxnnAu9Vp8N'\n",
    "#prefix = '1cycle'\n",
    "#url = 'https://drive.google.com/uc?id=1j46elyFZtkmnmCehlntMi0eX0Tp5nnav'\n",
    "#prefix = 'helper'\n",
    "#url = 'https://drive.google.com/uc?id=1iSP_YKFs56d5cRRTEMzfedwRxrx-nXWO'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061a428",
   "metadata": {},
   "source": [
    "## 스토리헬퍼 샘플 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac09f2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scripts_file = f'data/scripts_{prefix}.json'\n",
    "#zip_file = f'data/scripts_{prefix}.zip'\n",
    "#gdown.download(url, zip_file, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef689b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip $zip_file \n",
    "#!mv -f 'final.json' $scripts_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af38109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import json\n",
    "\n",
    "#with open(scripts_file) as f:\n",
    "#    data_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c880d607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': '01_0017_01',\n",
       " 'storyline': 'C001은 지하철 안에서 졸다가 깨어 내리는데 두 여자아이를 발견하고 섬찟한다.',\n",
       " 'script': ['C001은 지하철 노약자석 한구석에서 졸고 있다.',\n",
       "  'C001은 졸다가 눈을 가늘게 떴을 때 어떤 엄마와 아이를 본다.',\n",
       "  'C001은 열차가 문을 열고 닫는 동안 계속 졸다가 종착역임을 알게 되고 빠져나온다.',\n",
       "  'C001은 열차 안에 두 여자아이가 잠든 채로 문이 닫히고 출발하는 것을 본다.',\n",
       "  'C001은 섬찟하지만, 잠에서 막 깨어 피곤해한다.',\n",
       "  'C001은 집으로 들어가 부엌으로 향한다.',\n",
       "  '뭐 해?',\n",
       "  '놀래라. 소리도 없이 들어오네? 귀신인 줄 알았어. 밖에 비 와?',\n",
       "  'C001은 수건으로 머리를 닦으며 말한다.',\n",
       "  '제대로 된 우산 하나 있었는데 지난번에 차에 두고 내렸네.',\n",
       "  '할 수 없네. 갈게. 피곤해 보이니까 잘 쉬고.']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 데이터 출력\n",
    "data_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618293c6",
   "metadata": {},
   "source": [
    "**후처리**\n",
    "1. `\\n`을 제거한다. \"부엌에서 일하게 된 마리오\\n인부들 사이에서 인기만점인 베아트리체\"  \n",
    "   ==> 필요없는 것 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d48b59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비정상적 white character가 없는지 확인\n",
    "for idx, data in enumerate(data_dict):\n",
    "    #data['storyline'] = data['storyline'].replace('\\n', ' ')\n",
    "    for i, context in enumerate(data['script']):\n",
    "        #if '\\n' in context:\n",
    "        if '부엌에서 일하게' in context:\n",
    "            print(idx, i, context)\n",
    "            print('\"%s%s\"'%(context[9],context[10]))\n",
    "            print(context[10] == ' ')\n",
    "        #data['script'][i] = context.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58e2ce",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b08482",
   "metadata": {},
   "source": [
    "### kobigbird pretrained model을 이용한 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb68ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('monologg/kobigbird-bert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab61f27",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e81a5672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all suitable sessions:  100077\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "EOS_ID = tokenizer.sep_token_id\n",
    "\n",
    "positive_sessions = []\n",
    "positive_str = []\n",
    "positive_ids = []\n",
    "for i, unit_data in enumerate(data_dict):\n",
    "    unit_contexts = [tokenizer.tokenize(text) for text in unit_data['script'] + ['[SEP]'] ]\n",
    "    while [] in unit_contexts:\n",
    "        print('empty string in the script. removing..., id=', i)\n",
    "        index = unit_contexts.index([])\n",
    "        #print(\"'{%s}'\"%unit_data['script'][index])\n",
    "        del unit_contexts[index]\n",
    "        #unit_contexts.remove([])\n",
    "        del unit_data['script'][index]\n",
    "    if len(unit_contexts) <= 1:\n",
    "        print('empty scripts. skipping..., id=', i)\n",
    "        continue\n",
    "    unit_narrative = tokenizer.tokenize(unit_data['storyline'])\n",
    "    if len(unit_narrative) == 0:\n",
    "        print('empty narrative. skipping, id=', i)\n",
    "        continue\n",
    "    positive_sessions.append([unit_contexts, unit_narrative, 1])\n",
    "    positive_str.append(unit_data)\n",
    "    positive_ids.append(unit_data['uid'])\n",
    "print(\"all suitable sessions: \", len(positive_sessions))\n",
    "\n",
    "# reproducibility를 위한 random seed 설정\n",
    "np.random.seed(42)\n",
    "\n",
    "# split policy 변경으로 shuffle 안함\n",
    "# random shuffle data\n",
    "#np.random.shuffle(positive_sessions)\n",
    "#np.random.seed(42)\n",
    "#np.random.shuffle(positive_str)\n",
    "#np.random.seed(42)\n",
    "#np.random.shuffle(positive_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a2bb72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01_0017_01',\n",
       " '01_0017_02',\n",
       " '01_0017_03',\n",
       " '01_0017_04',\n",
       " '01_0017_05',\n",
       " '01_0017_06',\n",
       " '01_0017_07',\n",
       " '01_0017_08',\n",
       " '01_0017_09',\n",
       " '01_0017_10']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc46677c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train = 79782 , val = 10069 , test = 10226\n"
     ]
    }
   ],
   "source": [
    "#train_num = int(len(positive_sessions) * 0.9)\n",
    "#dev_test_num = int(len(positive_sessions) * 0.05)\n",
    "train_sessions, dev_sessions, test_sessions = positive_sessions[:train_num], positive_sessions[train_num: train_num + val_num], positive_sessions[train_num + val_num:]\n",
    "print('number of train =', len(train_sessions), ', val =', len(dev_sessions), ', test =', len(test_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "132fe371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word2vec training sentences = 1245934\n"
     ]
    }
   ],
   "source": [
    "train_texts = []\n",
    "for train_session in train_sessions:\n",
    "    train_texts += train_session[0]\n",
    "    train_texts.append(train_session[1])\n",
    "print('number of word2vec training sentences =', len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7540667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# word2vec 학습\n",
    "model = Word2Vec(sentences = train_texts, vector_size = 200, window = 7, min_count = 5, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52e2e01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of words = 18868\n",
      "first word = \"C\"\n",
      "last word = \"표고\"\n"
     ]
    }
   ],
   "source": [
    "print('total num of words =', len(model.wv.key_to_index))\n",
    "print('first word = \"%s\"'%model.wv.index_to_key[0])\n",
    "print('last word = \"%s\"'%model.wv.index_to_key[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4707535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('친구', 0.6640264391899109), ('지인', 0.6476936936378479), ('식구', 0.6278515458106995), ('아이', 0.592509925365448), ('동생', 0.5853767991065979), ('사람', 0.5754315853118896), ('백성', 0.571042001247406), ('부대원', 0.5707253217697144), ('자녀', 0.5706323981285095), ('아들', 0.5701492428779602)]\n"
     ]
    }
   ],
   "source": [
    "# word2vec이 잘 학습되었는지 여러가지 테스트를 수행하자.\n",
    "print(model.wv.most_similar(\"가족\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6ad5d7",
   "metadata": {},
   "source": [
    "## 데이터 저장\n",
    "\n",
    "`embeddings.pkl`과 `vocab.txt`를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8453ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/vocab_{prefix}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for i, key in enumerate(model.wv.index_to_key):\n",
    "        file.write('%s\\t%i\\n'%(key, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67a3bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "new_embeddings = np.array([[0.]*200],dtype='float32') \n",
    "for i in range(len(model.wv.index_to_key)):\n",
    "    new_embeddings = np.append(new_embeddings, [model.wv.get_vector(i)], axis=0)\n",
    "\n",
    "with open(f'data/embeddings_{prefix}.pkl', 'wb') as f:\n",
    "    pickle.dump(new_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f435a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"data/word2vec_{prefix}.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4ec99",
   "metadata": {},
   "source": [
    "# 학습 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "066fc318",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_ID = model.wv.key_to_index['[SEP]']+1\n",
    "UNK_ID = model.wv.key_to_index['[UNK]']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a86226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vocab = {}\n",
    "\n",
    "with open(f\"data/vocab_{prefix}.txt\", \"r\", encoding=\"utf-8\") as fr:\n",
    "    for idx, line in enumerate(fr):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        vocab[line[0]] = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0501f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample id 출력 확인\n",
    "vocab['가족']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611b33b",
   "metadata": {},
   "source": [
    "**positive data 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f165912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = []\n",
    "positive_str2 = []\n",
    "\n",
    "for unit, unit_str in zip(positive_sessions, positive_str):\n",
    "    narrative = unit[1]\n",
    "    #print(narrative)\n",
    "    context = unit[0]\n",
    "    narrative_id = [vocab.get(word, UNK_ID) for word in narrative]\n",
    "    context_id = [[vocab.get(word, UNK_ID) for word in sent] for sent in context]\n",
    "    if len(narrative_id) == 0 or len(context_id) == 0:\n",
    "        print('empty narrative found. skipping...')\n",
    "        #print(unit[0])\n",
    "        #print(unit[1])\n",
    "        print(unit_str)\n",
    "        continue\n",
    "    data = [context_id, narrative_id, 1]\n",
    "    positive_data.append(data)\n",
    "    positive_str2.append(unit_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a74d8151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100077, 100077, 100077)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_str), len(positive_str2), len(positive_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9944ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev, test = positive_data[:train_num], positive_data[train_num: train_num + val_num], positive_data[train_num + val_num:]\n",
    "train_ids, dev_ids, test_ids = positive_ids[:train_num], positive_ids[train_num: train_num + val_num], positive_ids[train_num + val_num:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22242ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 3, 7, 13, 2047, 18262, 967, 7636, 31, 2281, 14, 20, 11, 2]], [1, 3, 7, 13, 2281, 178, 180, 5, 9876, 15, 5798, 5, 176, 507, 173, 35, 213, 10, 64, 2], [1, 3, 7, 13, 2047, 47, 31, 2281, 178, 630, 28, 672, 72, 246, 187, 2332, 10, 135, 65, 1540, 2], [1, 3, 7, 13, 2281, 178, 180, 5, 9876, 15, 5798, 5, 176, 507, 173, 35, 213, 10, 64, 2], 1]\n",
      "[[[1, 3, 7, 13, 2047, 18262, 967, 7636, 31, 2281, 14, 20, 11, 2]], [246, 2637, 6, 489, 38, 1874, 869, 12040, 9177, 10, 1561, 22, 15, 312, 123, 2], [1, 3, 7, 13, 2047, 47, 31, 2281, 178, 630, 28, 672, 72, 246, 187, 2332, 10, 135, 65, 1540, 2], [1, 3, 7, 13, 2281, 178, 180, 5, 9876, 15, 5798, 5, 176, 507, 173, 35, 213, 10, 64, 2], 0]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "train_all, dev_all, test_all = [], [], []\n",
    "for context_id, narrative_id, _ in train:\n",
    "    num_context = len(context_id)\n",
    "    for i in range(1, num_context):\n",
    "        context = context_id[:i]\n",
    "        response = context_id[i]\n",
    "        train_all.append([context, response, narrative_id, response, 1])\n",
    "        flag = True\n",
    "        while flag:\n",
    "            random_idx = random.randint(0, len(positive_data) - 1)\n",
    "            random_context = positive_data[random_idx][0]\n",
    "            random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "            random_response = random_context[random_idx_2]\n",
    "            if len(response) != len(random_response):\n",
    "                flag = False\n",
    "                train_all.append([context, random_response, narrative_id, response, 0])\n",
    "            else:\n",
    "                for idx, wid in enumerate(response):\n",
    "                    if wid != random_response[idx]:\n",
    "                        flag = False\n",
    "                        train_all.append([context, random_response, narrative_id, response, 0])\n",
    "                        break\n",
    "print(train_all[0]) \n",
    "print(train_all[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "287d8fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 3, 7, 6, 489, 8, 156, 2967, 132, 52, 136, 11, 2]], [1, 3, 7, 17, 2566, 8, 2312, 3116, 9, 132, 52, 20, 11, 2], [1, 3, 7, 6, 2312, 3116, 8, 15, 478, 1, 3, 12, 6, 10, 185, 388, 5, 144, 22, 59, 200, 16, 2], [1, 3, 7, 17, 2566, 8, 2312, 3116, 9, 132, 52, 20, 11, 2], 1] [[[1, 3, 7, 6, 489, 8, 156, 2967, 132, 52, 136, 11, 2]], [1, 3, 7, 25, 1, 3, 12, 25, 1, 3, 19, 25, 1, 3, 23, 4, 617, 705, 325, 10, 48, 59, 198, 6077, 564, 8, 132, 52, 136, 11, 2], [1, 3, 7, 6, 2312, 3116, 8, 15, 478, 1, 3, 12, 6, 10, 185, 388, 5, 144, 22, 59, 200, 16, 2], [1, 3, 7, 17, 2566, 8, 2312, 3116, 9, 132, 52, 20, 11, 2], 0] [[[1, 3, 7, 6, 489, 8, 156, 2967, 132, 52, 136, 11, 2]], [6474, 2903, 4, 1, 3, 12, 5, 630, 1967, 236, 76, 17, 3815, 8, 20, 4, 815, 41, 5, 410, 3200, 11, 2], [1, 3, 7, 6, 2312, 3116, 8, 15, 478, 1, 3, 12, 6, 10, 185, 388, 5, 144, 22, 59, 200, 16, 2], [1, 3, 7, 17, 2566, 8, 2312, 3116, 9, 132, 52, 20, 11, 2], 0]\n"
     ]
    }
   ],
   "source": [
    "dev_all_ids = []\n",
    "for i_dev, (context_id, narrative_id, _) in enumerate(dev):\n",
    "    num_context = len(context_id)\n",
    "    for i in range(1, num_context):\n",
    "        context = context_id[:i]\n",
    "        response = context_id[i]\n",
    "        dev_all.append([context, response, narrative_id, response, 1])\n",
    "        dev_all_ids.append(dev_ids[i_dev])\n",
    "        count = 0\n",
    "        negative_samples = []\n",
    "        # fix count 버그\n",
    "        while count < 8:\n",
    "            random_idx = random.randint(0, len(positive_data) - 1)\n",
    "            random_context = positive_data[random_idx][0]\n",
    "            random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "            random_response = random_context[random_idx_2]\n",
    "            if random_response not in negative_samples and random_response != [EOS_ID]:\n",
    "                if len(response) != len(random_response):\n",
    "                    dev_all.append([context, random_response, narrative_id, response, 0])\n",
    "                    negative_samples.append(random_response)\n",
    "                    dev_all_ids.append(dev_ids[i_dev])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    for idx, wid in enumerate(response):\n",
    "                        if wid != random_response[idx]:\n",
    "                            dev_all.append([context, random_response, narrative_id, response, 0])\n",
    "                            negative_samples.append(random_response)\n",
    "                            dev_all_ids.append(dev_ids[i_dev])\n",
    "                            count += 1\n",
    "                            break\n",
    "        if response == [EOS_ID]:\n",
    "            dev_all.append([context, [EOS_ID], narrative_id, response, 1])\n",
    "        else:\n",
    "            dev_all.append([context, [EOS_ID], narrative_id, response, 0])\n",
    "        dev_all_ids.append(dev_ids[i_dev])\n",
    "print(dev_all[0], dev_all[1], dev_all[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d77f6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1, 3, 7, 13, 261, 7703, 5, 261, 259, 1931, 2954, 917, 10, 293, 728, 10, 1400, 2]], [890, 20, 4, 1, 3, 7, 17, 151, 8, 6205, 6, 4022, 11, 2], [1, 3, 7, 13, 422, 31, 630, 28, 1307, 10, 293, 381, 8, 326, 16, 2], [890, 20, 4, 1, 3, 7, 17, 151, 8, 6205, 6, 4022, 11, 2], 1] [[[1, 3, 7, 13, 261, 7703, 5, 261, 259, 1931, 2954, 917, 10, 293, 728, 10, 1400, 2]], [511, 10, 48, 4, 1, 3, 44, 8, 15, 1, 3, 12, 4, 1234, 382, 174, 139, 454, 14, 24, 16, 2], [1, 3, 7, 13, 422, 31, 630, 28, 1307, 10, 293, 381, 8, 326, 16, 2], [890, 20, 4, 1, 3, 7, 17, 151, 8, 6205, 6, 4022, 11, 2], 0] [[[1, 3, 7, 13, 261, 7703, 5, 261, 259, 1931, 2954, 917, 10, 293, 728, 10, 1400, 2]], [109, 25, 139, 439, 134, 2, 286, 297, 127, 34, 21], [1, 3, 7, 13, 422, 31, 630, 28, 1307, 10, 293, 381, 8, 326, 16, 2], [890, 20, 4, 1, 3, 7, 17, 151, 8, 6205, 6, 4022, 11, 2], 0]\n"
     ]
    }
   ],
   "source": [
    "test_all = []\n",
    "test_all_ids = []\n",
    "test_num_context = []\n",
    "for i_test, (context_id, narrative_id, _) in enumerate(test):\n",
    "    num_context = len(context_id)\n",
    "    test_num_context.append(num_context-1)\n",
    "    for i in range(1, num_context):\n",
    "        context = context_id[:i]\n",
    "        response = context_id[i]\n",
    "        test_all.append([context, response, narrative_id, response, 1])\n",
    "        test_all_ids.append(test_ids[i_test])\n",
    "        count = 0\n",
    "        negative_samples = []\n",
    "        # fix count 버그\n",
    "        while count < 8:\n",
    "            random_idx = random.randint(0, len(positive_data) - 1)\n",
    "            random_context = positive_data[random_idx][0]\n",
    "            random_idx_2 = random.randint(0, len(random_context) - 1)\n",
    "            random_response = random_context[random_idx_2]\n",
    "            if random_response not in negative_samples and random_response != [EOS_ID]:\n",
    "                if len(response) != len(random_response):\n",
    "                    test_all.append([context, random_response, narrative_id, response, 0])\n",
    "                    negative_samples.append(random_response)\n",
    "                    test_all_ids.append(test_ids[i_test])\n",
    "                    count += 1\n",
    "                else:\n",
    "                    for idx, id in enumerate(response):\n",
    "                        if id != random_response[idx]:\n",
    "                            test_all.append([context, random_response, narrative_id, response, 0])\n",
    "                            negative_samples.append(random_response)\n",
    "                            test_all_ids.append(test_ids[i_test])\n",
    "                            count += 1\n",
    "                            break\n",
    "        if response == [EOS_ID]:\n",
    "            test_all.append([context, [EOS_ID], narrative_id, response, 1])\n",
    "        else:\n",
    "            test_all.append([context, [EOS_ID], narrative_id, response, 0])\n",
    "        test_all_ids.append(test_ids[i_test])\n",
    "if test_num > 0:\n",
    "    print(test_all[0], test_all[1], test_all[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f3eaafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1443410, 1443410)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_all_ids), len(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5c5b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train count = 2172740\n",
      "total val count = 1458780\n",
      "total test count = 1443410\n"
     ]
    }
   ],
   "source": [
    "print('total train count =', len(train_all))\n",
    "print('total val count =', len(dev_all))\n",
    "print('total test count =', len(test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cb7931a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144341"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(test_num_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47cd19f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_from_nonfixed_2d_array(aa, max_sentence_len=50, max_num_utterance=10, padding_value=0):\n",
    "    PAD_SEQUENCE = np.array([0] * max_sentence_len)\n",
    "    rows = np.empty([0, max_sentence_len], dtype='int')\n",
    "    aa = aa[-max_num_utterance:]\n",
    "    for a in aa:\n",
    "        sentence_len = len(a)\n",
    "        if sentence_len < max_sentence_len:\n",
    "            rows  = np.append(rows, [np.pad(a, (0, max_sentence_len-sentence_len), 'constant', constant_values=padding_value)[:max_sentence_len]], axis=0)\n",
    "        else:\n",
    "            rows = np.append(rows, [a[:max_sentence_len]], axis=0)\n",
    "    num_utterance = len(aa)\n",
    "    if num_utterance < max_num_utterance:\n",
    "        rows = np.append(rows, [PAD_SEQUENCE]*(max_num_utterance-num_utterance), axis=0)\n",
    "    # add empty +1 sentence\n",
    "    rows = np.append(rows, [PAD_SEQUENCE], axis=0)\n",
    "    #return np.concatenate(rows, axis=0).reshape(-1, max_sentence_len)\n",
    "    return rows\n",
    "\n",
    "def get_numpy_from_nonfixed_1d_array(a, max_sentence_len=50, padding_value=0):\n",
    "    sentence_len = len(a)\n",
    "    if sentence_len < max_sentence_len:\n",
    "        return np.pad(a, (0, max_sentence_len-sentence_len), 'constant', constant_values=padding_value)\n",
    "    else:\n",
    "        return np.array(a[:max_sentence_len])\n",
    "\n",
    "cc_test_data = [\n",
    "        [1,2],\n",
    "        [4,5,6],\n",
    "        [7]\n",
    "     ]\n",
    "#get_numpy_from_nonfixed_2d_array(cc_test_data, max_sentence_len=5, max_num_utterance=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "475ebe4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b064641e4c54cd39f9710329e1d43df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2172740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a85cd052f6462fa8b090aa6a17d6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1458780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9555b025e15a46e897b61ba4b52a9cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1443410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#try:\n",
    "#    __IPYTHON__\n",
    "#    from tqdm.notebook import tqdm\n",
    "#except NameError:\n",
    "#    from tqdm import tqdm\n",
    "try:\n",
    "    __IPYTHON__\n",
    "    import sys\n",
    "    if 'ipykernel' in sys.modules:\n",
    "        pass\n",
    "    elif 'IPython' in sys.modules:\n",
    "        raise\n",
    "    else:\n",
    "        raise\n",
    "    from tqdm.notebook import tqdm\n",
    "except:\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "def pad_process(data, max_sentence_len=50, max_num_utterance=10):\n",
    "    utterance = []\n",
    "    response = []\n",
    "    narrative = []\n",
    "    gt_response = []\n",
    "    y_true = []\n",
    "    for unit in tqdm(data):\n",
    "        utterance.append(get_numpy_from_nonfixed_2d_array(unit[0]))\n",
    "        response.append(get_numpy_from_nonfixed_1d_array(unit[1]))\n",
    "        narrative.append(get_numpy_from_nonfixed_1d_array(unit[2]))\n",
    "        gt_response.append(get_numpy_from_nonfixed_1d_array(unit[3]))\n",
    "        y_true.append(unit[4])\n",
    "    utterance = np.stack(utterance)\n",
    "    response = np.stack(response)\n",
    "    narrative = np.stack(narrative)\n",
    "    gt_response = np.stack(gt_response)\n",
    "    y_true = np.stack(y_true)\n",
    "    return (utterance, response, narrative, gt_response, y_true)\n",
    "\n",
    "train_pad = pad_process(train_all)\n",
    "dev_pad = pad_process(dev_all)\n",
    "if test_num > 0:    \n",
    "    test_pad = pad_process(test_all)\n",
    "else:\n",
    "    test_pad = ([], [], [], [], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003946db",
   "metadata": {},
   "source": [
    "**학습데이터셋 저장**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4d8dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/train_{prefix}.pkl', 'wb') as f:\n",
    "    pickle.dump(train_pad, f)\n",
    "with open(f'data/dev_{prefix}.pkl', 'wb') as f:\n",
    "    pickle.dump(dev_pad, f)\n",
    "with open(f'data/test_{prefix}.pkl', 'wb') as f:\n",
    "    pickle.dump(test_pad, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3ac8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/positive_{prefix}.pkl', \"wb\") as f:\n",
    "    pickle.dump(positive_data, f)\n",
    "with open(f'data/positive_str_{prefix}.pkl', \"wb\") as f:\n",
    "    pickle.dump(positive_str2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "642fbe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/test_all_ids_{prefix}.pkl', \"wb\") as f:\n",
    "    pickle.dump(test_all_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0f0df0f7-38e2-40e0-84f0-bcfcbb86fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ~/.cache/huggingface/datasets/story_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "449089fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for unit, unit_str in zip (positive_data, positive_str2):\n",
    "    len_unit = len(unit[0])\n",
    "    len_unit_str = len(unit_str['script'])\n",
    "    if len_unit != len_unit_str+1:\n",
    "        print(len_unit, len_unit_str)\n",
    "    #print(unit[0])\n",
    "    #print(unit_str['script'])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f477e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dat(index, data_pad, ids = None):\n",
    "    utterances = data_pad[0][index]\n",
    "    response = data_pad[1][index]\n",
    "    narrative = data_pad[2][index]\n",
    "    gt_response = data_pad[3][index]\n",
    "    y_true = data_pad[4][index]\n",
    "    narrative = narrative[narrative!=0]\n",
    "    response = response[response!=0]\n",
    "    gt_response = gt_response[gt_response!=0]\n",
    "    #print([model.wv.index_to_key[k-1] for k in narrative])\n",
    "    narrative_str = tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in narrative])\n",
    "    response_str = tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in response])\n",
    "    gt_response_str = tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in gt_response])\n",
    "    #print(y_true)\n",
    "    utterance_str = ['']*10\n",
    "    for i in range(10):\n",
    "        utterance = utterances[i]\n",
    "        utterance = utterance[utterance!=0]\n",
    "        if len(utterance) == 0:\n",
    "            break\n",
    "        utterance_str[i] =  tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in utterance])\n",
    "    #print()\n",
    "    if ids == None:\n",
    "        id_ = None\n",
    "    else:\n",
    "        id_ = ids[index]\n",
    "    return id_, narrative_str, response_str, gt_response_str, y_true, utterance_str\n",
    "    \n",
    "def browse_dat(index, data_pad):\n",
    "    utterances = data_pad[0][index]\n",
    "    response = data_pad[1][index]\n",
    "    narrative = data_pad[2][index]\n",
    "    gt_response = data_pad[3][index]\n",
    "    y_true = data_pad[4][index]\n",
    "    narrative = narrative[narrative!=0]\n",
    "    response = response[response!=0]\n",
    "    gt_response = gt_response[gt_response!=0]\n",
    "    #print([model.wv.index_to_key[k-1] for k in narrative])\n",
    "    print('N:', tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in narrative]))\n",
    "    print('R:', tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in response]))\n",
    "    print('T:', tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in gt_response]))\n",
    "    print(y_true)\n",
    "    for i in range(10):\n",
    "        utterance = utterances[i]\n",
    "        utterance = utterance[utterance!=0]\n",
    "        if len(utterance) == 0:\n",
    "            break\n",
    "        print('U:', tokenizer.convert_tokens_to_string([model.wv.index_to_key[k-1] for k in utterance]))\n",
    "    print()\n",
    "    \n",
    "\n",
    "#browse_dat(0, train_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd7b37f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: [SEP]\n",
      "T: [SEP]\n",
      "1\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: C005은 어느 까다로운 중년 여자에게 우산을 판다.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: 진정하고 앉아라.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: 주상복합빌딩은 초고층으로 2개의 빌딩이 구름다리로 연결되어 있습니다.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: 그런데 한가지 이상한 점은 왜 자꾸 죽은 사람의 인격에 집착하는지 모르겠어요.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: C002이 C006에게 뭐 하냐고 묻는다.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: C001는 C006의 목소리에 사과한다.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: C005은 누가 술 2를 더 많이 마시는 [UNK] 내기하는 걸 즐긴대.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: C011는 숨어서 C001을 향해 총을 쏜다.\n",
      "T: [SEP]\n",
      "0\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n",
      "N: C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.\n",
      "R: [SEP]\n",
      "T: [SEP]\n",
      "1\n",
      "U: 방 밖에서 들리는 소리에 C001은 잠에서 깬다.\n",
      "U: C003가 더운물과 찬물을 섞어 세숫물을 만든다.\n",
      "U: 수돗가에서 C001이 이를 닦고 있다.\n",
      "U: C001은 스쿠터를 타고 거리를 달린다.\n",
      "U: C001은 학교 담 너머 학생들의 방학식을 지켜본다.\n",
      "U: 운동장을 지켜보던 C001은 오토바이를 타고 거리를 달린다.\n",
      "U: 병원 대기석에 앉아 순서를 기다리던 C001은 어린 환자를 보고 웃는다.\n",
      "U: 어린 환자도 C001을 보며 웃는다.\n",
      "U: 철봉에 올라선 C001이 힘을 주어 한 바퀴를 돈다.\n",
      "U: 사람은 언젠가는 모두 죽는다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if test_num > 0:\n",
    "    for i in range(110,120): \n",
    "        browse_dat(i, test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82471e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b4d3606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Narrative', 'Response', 'GT_Response', 'y_true', 'score', 'R2@1', 'R10@1', 'R10@2', 'R10@5', 'MRR', 'AVG', 'U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08', 'U09', 'U10']\n"
     ]
    }
   ],
   "source": [
    "column_names = ['id', 'Narrative', 'Response', 'GT_Response', 'y_true', 'score', 'R2@1', 'R10@1', 'R10@2', 'R10@5', 'MRR', 'AVG']\n",
    "for i in range(10):\n",
    "    column_names.append('U%02d'%(i+1))\n",
    "print(column_names)\n",
    "df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e54583f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7b6b5cfa5d48c0965f4abfc3b41db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1443410 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(test_all_ids)\n",
    "data_dict_all = []\n",
    "for i in tqdm(range(n)):\n",
    "    id_, narrative_str, response_str, gt_response_str, y_true, utterance_str = get_dat(i, test_pad, test_all_ids)\n",
    "    data_dict = { }\n",
    "    data_dict['id'] = id_\n",
    "    data_dict['Narrative'] = narrative_str\n",
    "    data_dict['Response'] = response_str\n",
    "    data_dict['GT_Response'] = gt_response_str\n",
    "    data_dict['y_true'] = y_true\n",
    "    for i in range(10):\n",
    "        data_dict[f'U%02d'%(i+1)] = utterance_str[i]\n",
    "    #new_row = pd.Series(data_dict)\n",
    "    #df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "    data_dict_all.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f01f0132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "354aa55f-1f0e-46f2-99f1-32764ba3ce0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Response</th>\n",
       "      <th>GT_Response</th>\n",
       "      <th>y_true</th>\n",
       "      <th>U01</th>\n",
       "      <th>U02</th>\n",
       "      <th>U03</th>\n",
       "      <th>U04</th>\n",
       "      <th>U05</th>\n",
       "      <th>U06</th>\n",
       "      <th>U07</th>\n",
       "      <th>U08</th>\n",
       "      <th>U09</th>\n",
       "      <th>U10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01_0022_01</td>\n",
       "      <td>C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.</td>\n",
       "      <td>자고 있는 C001의 얼굴에 햇살이 비친다.</td>\n",
       "      <td>자고 있는 C001의 얼굴에 햇살이 비친다.</td>\n",
       "      <td>1</td>\n",
       "      <td>C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01_0022_01</td>\n",
       "      <td>C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.</td>\n",
       "      <td>식사를 하는 C007에게 C002는 다가와 잠시 얘기 좀 하자고 말한다.</td>\n",
       "      <td>자고 있는 C001의 얼굴에 햇살이 비친다.</td>\n",
       "      <td>0</td>\n",
       "      <td>C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01_0022_01</td>\n",
       "      <td>C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.</td>\n",
       "      <td>네, 좀 그렇죠. 그렇게 보이나요?</td>\n",
       "      <td>자고 있는 C001의 얼굴에 햇살이 비친다.</td>\n",
       "      <td>0</td>\n",
       "      <td>C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01_0022_01</td>\n",
       "      <td>C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.</td>\n",
       "      <td>C020가 한국말을 못 하자 C005이 당황하여 C017에게 묻는다.</td>\n",
       "      <td>자고 있는 C001의 얼굴에 햇살이 비친다.</td>\n",
       "      <td>0</td>\n",
       "      <td>C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01_0022_01</td>\n",
       "      <td>C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.</td>\n",
       "      <td>C009이 열받아서 책장을 주먹으로 내리친다.</td>\n",
       "      <td>자고 있는 C001의 얼굴에 햇살이 비친다.</td>\n",
       "      <td>0</td>\n",
       "      <td>C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443405</th>\n",
       "      <td>04_3671_11</td>\n",
       "      <td>꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.</td>\n",
       "      <td>버스에 탄 C001이 스포츠센터 앞의 C002 자전거를 찾는다.</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>0</td>\n",
       "      <td>파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.</td>\n",
       "      <td>순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?</td>\n",
       "      <td>너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.</td>\n",
       "      <td>C001가 C010를 못마땅한 눈으로 쳐다본다.</td>\n",
       "      <td>신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...</td>\n",
       "      <td>C010가 뒤를 돌아 C001를 바라본다.</td>\n",
       "      <td>아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.</td>\n",
       "      <td>C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.</td>\n",
       "      <td>오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.</td>\n",
       "      <td>그래. 인정해주지.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443406</th>\n",
       "      <td>04_3671_11</td>\n",
       "      <td>꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.</td>\n",
       "      <td>C005 얼굴에 먹칠하면 안 돼. 참자.</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>0</td>\n",
       "      <td>파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.</td>\n",
       "      <td>순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?</td>\n",
       "      <td>너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.</td>\n",
       "      <td>C001가 C010를 못마땅한 눈으로 쳐다본다.</td>\n",
       "      <td>신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...</td>\n",
       "      <td>C010가 뒤를 돌아 C001를 바라본다.</td>\n",
       "      <td>아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.</td>\n",
       "      <td>C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.</td>\n",
       "      <td>오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.</td>\n",
       "      <td>그래. 인정해주지.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443407</th>\n",
       "      <td>04_3671_11</td>\n",
       "      <td>꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.</td>\n",
       "      <td>호텔 직원1이 C003과 C002의 짐을 옮겨준다.</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>0</td>\n",
       "      <td>파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.</td>\n",
       "      <td>순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?</td>\n",
       "      <td>너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.</td>\n",
       "      <td>C001가 C010를 못마땅한 눈으로 쳐다본다.</td>\n",
       "      <td>신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...</td>\n",
       "      <td>C010가 뒤를 돌아 C001를 바라본다.</td>\n",
       "      <td>아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.</td>\n",
       "      <td>C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.</td>\n",
       "      <td>오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.</td>\n",
       "      <td>그래. 인정해주지.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443408</th>\n",
       "      <td>04_3671_11</td>\n",
       "      <td>꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.</td>\n",
       "      <td>C001은 자신의 집에서 찾아온 필름 통에서 필름을 꺼내어 암호를 확인한다.</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>0</td>\n",
       "      <td>파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.</td>\n",
       "      <td>순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?</td>\n",
       "      <td>너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.</td>\n",
       "      <td>C001가 C010를 못마땅한 눈으로 쳐다본다.</td>\n",
       "      <td>신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...</td>\n",
       "      <td>C010가 뒤를 돌아 C001를 바라본다.</td>\n",
       "      <td>아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.</td>\n",
       "      <td>C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.</td>\n",
       "      <td>오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.</td>\n",
       "      <td>그래. 인정해주지.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443409</th>\n",
       "      <td>04_3671_11</td>\n",
       "      <td>꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "      <td>1</td>\n",
       "      <td>파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.</td>\n",
       "      <td>순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?</td>\n",
       "      <td>너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.</td>\n",
       "      <td>C001가 C010를 못마땅한 눈으로 쳐다본다.</td>\n",
       "      <td>신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...</td>\n",
       "      <td>C010가 뒤를 돌아 C001를 바라본다.</td>\n",
       "      <td>아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.</td>\n",
       "      <td>C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.</td>\n",
       "      <td>오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.</td>\n",
       "      <td>그래. 인정해주지.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1443410 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                           Narrative  \\\n",
       "0        01_0022_01     C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.   \n",
       "1        01_0022_01     C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.   \n",
       "2        01_0022_01     C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.   \n",
       "3        01_0022_01     C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.   \n",
       "4        01_0022_01     C001은 잠에서 깨어 오토바이를 타고 병원에 도착한다.   \n",
       "...             ...                                 ...   \n",
       "1443405  04_3671_11  꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.   \n",
       "1443406  04_3671_11  꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.   \n",
       "1443407  04_3671_11  꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.   \n",
       "1443408  04_3671_11  꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.   \n",
       "1443409  04_3671_11  꿈에서 깨어난 C001는 C010와 정식으로 서로를 소개한다.   \n",
       "\n",
       "                                           Response               GT_Response  \\\n",
       "0                          자고 있는 C001의 얼굴에 햇살이 비친다.  자고 있는 C001의 얼굴에 햇살이 비친다.   \n",
       "1          식사를 하는 C007에게 C002는 다가와 잠시 얘기 좀 하자고 말한다.  자고 있는 C001의 얼굴에 햇살이 비친다.   \n",
       "2                               네, 좀 그렇죠. 그렇게 보이나요?  자고 있는 C001의 얼굴에 햇살이 비친다.   \n",
       "3            C020가 한국말을 못 하자 C005이 당황하여 C017에게 묻는다.  자고 있는 C001의 얼굴에 햇살이 비친다.   \n",
       "4                         C009이 열받아서 책장을 주먹으로 내리친다.  자고 있는 C001의 얼굴에 햇살이 비친다.   \n",
       "...                                             ...                       ...   \n",
       "1443405         버스에 탄 C001이 스포츠센터 앞의 C002 자전거를 찾는다.                     [SEP]   \n",
       "1443406                      C005 얼굴에 먹칠하면 안 돼. 참자.                     [SEP]   \n",
       "1443407                호텔 직원1이 C003과 C002의 짐을 옮겨준다.                     [SEP]   \n",
       "1443408  C001은 자신의 집에서 찾아온 필름 통에서 필름을 꺼내어 암호를 확인한다.                     [SEP]   \n",
       "1443409                                       [SEP]                     [SEP]   \n",
       "\n",
       "         y_true                                         U01  \\\n",
       "0             1             C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.   \n",
       "1             0             C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.   \n",
       "2             0             C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.   \n",
       "3             0             C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.   \n",
       "4             0             C001은 맞바람을 맞으며 스쿠터를 타고 거리를 달린다.   \n",
       "...         ...                                         ...   \n",
       "1443405       0  파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.   \n",
       "1443406       0  파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.   \n",
       "1443407       0  파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.   \n",
       "1443408       0  파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.   \n",
       "1443409       1  파편이 튈 위치 정도는 정확히 계산할 수 있어. 내 마법에 실수는 없으니까.   \n",
       "\n",
       "                                                U02  \\\n",
       "0                                                     \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     \n",
       "...                                             ...   \n",
       "1443405  순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?   \n",
       "1443406  순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?   \n",
       "1443407  순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?   \n",
       "1443408  순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?   \n",
       "1443409  순간이동? 그럼 무사히 도망친 거지? 아까 녀석이 계속 따라오진 않는 거지?   \n",
       "\n",
       "                                                     U03  \\\n",
       "0                                                          \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4                                                          \n",
       "...                                                  ...   \n",
       "1443405  너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.   \n",
       "1443406  너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.   \n",
       "1443407  너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.   \n",
       "1443408  너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.   \n",
       "1443409  너무 멀어서 쉽지 않겠지. 그래도 안심할 수 없으니 최대한 빨리 도시에 들어가야 해.   \n",
       "\n",
       "                                U04  \\\n",
       "0                                     \n",
       "1                                     \n",
       "2                                     \n",
       "3                                     \n",
       "4                                     \n",
       "...                             ...   \n",
       "1443405  C001가 C010를 못마땅한 눈으로 쳐다본다.   \n",
       "1443406  C001가 C010를 못마땅한 눈으로 쳐다본다.   \n",
       "1443407  C001가 C010를 못마땅한 눈으로 쳐다본다.   \n",
       "1443408  C001가 C010를 못마땅한 눈으로 쳐다본다.   \n",
       "1443409  C001가 C010를 못마땅한 눈으로 쳐다본다.   \n",
       "\n",
       "                                                       U05  \\\n",
       "0                                                            \n",
       "1                                                            \n",
       "2                                                            \n",
       "3                                                            \n",
       "4                                                            \n",
       "...                                                    ...   \n",
       "1443405  신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...   \n",
       "1443406  신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...   \n",
       "1443407  신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...   \n",
       "1443408  신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...   \n",
       "1443409  신의 이름을 갖고 있다면 힘과 용기를 혹은 지성과 교양은 최소한 있어야 할 텐데. ...   \n",
       "\n",
       "                             U06                                   U07  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3                                                                        \n",
       "4                                                                        \n",
       "...                          ...                                   ...   \n",
       "1443405  C010가 뒤를 돌아 C001를 바라본다.  아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.   \n",
       "1443406  C010가 뒤를 돌아 C001를 바라본다.  아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.   \n",
       "1443407  C010가 뒤를 돌아 C001를 바라본다.  아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.   \n",
       "1443408  C010가 뒤를 돌아 C001를 바라본다.  아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.   \n",
       "1443409  C010가 뒤를 돌아 C001를 바라본다.  아깐 이름만 말했나? 풀네임은 C010. 올해 20살인 마법사다.   \n",
       "\n",
       "                                              U08  \\\n",
       "0                                                   \n",
       "1                                                   \n",
       "2                                                   \n",
       "3                                                   \n",
       "4                                                   \n",
       "...                                           ...   \n",
       "1443405  C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.   \n",
       "1443406  C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.   \n",
       "1443407  C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.   \n",
       "1443408  C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.   \n",
       "1443409  C001가 C010를 향해 허공에 주먹을 내지르자, 바람이 강하게 인다.   \n",
       "\n",
       "                                           U09         U10  \n",
       "0                                                           \n",
       "1                                                           \n",
       "2                                                           \n",
       "3                                                           \n",
       "4                                                           \n",
       "...                                        ...         ...  \n",
       "1443405  오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.  그래. 인정해주지.  \n",
       "1443406  오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.  그래. 인정해주지.  \n",
       "1443407  오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.  그래. 인정해주지.  \n",
       "1443408  오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.  그래. 인정해주지.  \n",
       "1443409  오늘까지 C001. 내일부터 C001. 짐만 되는 어린애는 아니야.  그래. 인정해주지.  \n",
       "\n",
       "[1443410 rows x 15 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd97d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output rows are too large for excel\n",
    "# save to csv\n",
    "df.to_csv(f'test_output_{prefix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54a11abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'Narrative', 'Response', 'GT_Response', 'y_true', 'score', 'R2@1', 'R10@1', 'R10@2', 'R10@5', 'MRR', 'AVG', 'U01', 'U02', 'U03', 'U04', 'U05', 'U06', 'U07', 'U08', 'U09', 'U10']\n"
     ]
    }
   ],
   "source": [
    "column_names = ['id', 'Narrative', 'Response', 'GT_Response', 'y_true', 'score', 'R2@1', 'R10@1', 'R10@2', 'R10@5', 'MRR', 'AVG']\n",
    "for i in range(10):\n",
    "    column_names.append('U%02d'%(i+1))\n",
    "print(column_names)\n",
    "df = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44b58053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21ee3668c31479da95b148ee64437e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1458780 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(dev_all_ids)\n",
    "data_dict_all = []\n",
    "for i in tqdm(range(n)):\n",
    "    id_, narrative_str, response_str, gt_response_str, y_true, utterance_str = get_dat(i, dev_pad, dev_all_ids)\n",
    "    data_dict = { }\n",
    "    data_dict['id'] = id_\n",
    "    data_dict['Narrative'] = narrative_str\n",
    "    data_dict['Response'] = response_str\n",
    "    data_dict['GT_Response'] = gt_response_str\n",
    "    data_dict['y_true'] = y_true\n",
    "    for i in range(10):\n",
    "        data_dict[f'U%02d'%(i+1)] = utterance_str[i]\n",
    "    #new_row = pd.Series(data_dict)\n",
    "    #df = pd.concat([df, new_row.to_frame().T], ignore_index=True)\n",
    "    data_dict_all.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34a5e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data_dict_all)\n",
    "df.to_csv(f'dev_output_{prefix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07d906",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
