{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0170c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import *\n",
    "import numpy as np\n",
    "from torch.nn.parameter import Parameter\n",
    "import pickle\n",
    "from typing import Optional\n",
    "\n",
    "class layer_normalization(nn.Module):\n",
    "\n",
    "    def __init__(self, features, epsilon=1e-8):\n",
    "        '''Applies layer normalization.\n",
    "        Args:\n",
    "          epsilon: A floating number. A very small number for preventing ZeroDivision Error.\n",
    "        '''\n",
    "        super(layer_normalization, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.epsilon) + self.beta\n",
    "    \n",
    "class multihead_attention(nn.Module):\n",
    "\n",
    "    def __init__(self, num_units, num_heads=8, dropout_rate=0, causality=False):\n",
    "        '''Applies multihead attention.\n",
    "        Args:\n",
    "            num_units: A scalar. Attention size.\n",
    "            dropout_rate: A floating point number.\n",
    "            causality: Boolean. If true, units that reference the future are masked.\n",
    "            num_heads: An int. Number of heads.\n",
    "        '''\n",
    "        super(multihead_attention, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.causality = causality\n",
    "        self.Q_proj = nn.Sequential(nn.Linear(self.num_units, self.num_units), nn.ReLU())\n",
    "        self.K_proj = nn.Sequential(nn.Linear(self.num_units, self.num_units), nn.ReLU())\n",
    "        self.V_proj = nn.Sequential(nn.Linear(self.num_units, self.num_units), nn.ReLU())\n",
    "\n",
    "        self.output_dropout = nn.Dropout(p=self.dropout_rate)\n",
    "\n",
    "        self.normalization = layer_normalization(self.num_units)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        # keys, values: same shape of [N, T_k, C_k]\n",
    "        # queries: A 3d Variable with shape of [N, T_q, C_q]\n",
    "\n",
    "        print('q shape:', queries.shape)\n",
    "        # Linear projections\n",
    "        Q = self.Q_proj(queries)  # (N, T_q, C)\n",
    "        print('Q shape:', Q.shape)\n",
    "        K = self.K_proj(keys)  # (N, T_q, C)\n",
    "        V = self.V_proj(values)  # (N, T_q, C)\n",
    "\n",
    "        # Split and concat\n",
    "        Q_ = torch.cat(torch.chunk(Q, self.num_heads, dim=2), dim=0)  # (h*N, T_q, C/h)\n",
    "        K_ = torch.cat(torch.chunk(K, self.num_heads, dim=2), dim=0)  # (h*N, T_q, C/h)\n",
    "        V_ = torch.cat(torch.chunk(V, self.num_heads, dim=2), dim=0)  # (h*N, T_q, C/h)\n",
    "\n",
    "        # Multiplication\n",
    "        outputs = torch.bmm(Q_, K_.permute(0, 2, 1))  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (K_.size()[-1] ** 0.5)\n",
    "\n",
    "        # Key Masking\n",
    "        key_masks = torch.sign(torch.abs(torch.sum(keys, dim=-1)))  # (N, T_k)\n",
    "        key_masks = key_masks.repeat(self.num_heads, 1)  # (h*N, T_k)\n",
    "        key_masks = torch.unsqueeze(key_masks, 1).repeat(1, queries.size()[1], 1)  # (h*N, T_q, T_k)\n",
    "\n",
    "        padding = Variable(torch.ones(*outputs.size()).cuda() * (-2 ** 32 + 1))\n",
    "        condition = key_masks.eq(0.).float()\n",
    "        outputs = padding * condition + outputs * (1. - condition)\n",
    "\n",
    "        # Causality = Future blinding\n",
    "        if self.causality:\n",
    "            diag_vals = torch.ones(*outputs[0, :, :].size()).cuda()  # (T_q, T_k)\n",
    "            tril = torch.tril(diag_vals, diagonal=0)  # (T_q, T_k)\n",
    "            # print(tril)\n",
    "            masks = Variable(torch.unsqueeze(tril, 0).repeat(outputs.size()[0], 1, 1))  # (h*N, T_q, T_k)\n",
    "\n",
    "            padding = Variable(torch.ones(*masks.size()).cuda() * (-2 ** 32 + 1))\n",
    "            condition = masks.eq(0.).float()\n",
    "            outputs = padding * condition + outputs * (1. - condition)\n",
    "\n",
    "        # Activation\n",
    "        outputs = F.softmax(outputs, dim=-1)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Query Masking\n",
    "        query_masks = torch.sign(torch.abs(torch.sum(queries, dim=-1)))  # (N, T_q)\n",
    "        query_masks = query_masks.repeat(self.num_heads, 1)  # (h*N, T_q)\n",
    "        query_masks = torch.unsqueeze(query_masks, 2).repeat(1, 1, keys.size()[1])  # (h*N, T_q, T_k)\n",
    "        outputs = outputs * query_masks\n",
    "\n",
    "        # Dropouts\n",
    "        outputs = self.output_dropout(outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Weighted sum\n",
    "        outputs = torch.bmm(outputs, V_)  # (h*N, T_q, C/h)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = torch.cat(torch.chunk(outputs, self.num_heads, dim=0), dim=2)  # (N, T_q, C)\n",
    "\n",
    "        # Residual connection\n",
    "        outputs += queries\n",
    "\n",
    "        # Normalize\n",
    "        outputs = self.normalization(outputs)  # (N, T_q, C)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class feedforward(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_units=[2048, 512]):\n",
    "        '''Point-wise feed forward net.\n",
    "        Args:\n",
    "          in_channels: a number of channels of inputs\n",
    "          num_units: A list of two integers.\n",
    "        '''\n",
    "        super(feedforward, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_units = num_units\n",
    "\n",
    "        # nn.Linear is faster than nn.Conv1d\n",
    "        self.conv = False\n",
    "        if self.conv:\n",
    "            params = {'in_channels': self.in_channels, 'out_channels': self.num_units[0],\n",
    "                      'kernel_size': 1, 'stride': 1, 'bias': True}\n",
    "            self.conv1 = nn.Sequential(nn.Conv1d(**params), nn.ReLU())\n",
    "            params = {'in_channels': self.num_units[0], 'out_channels': self.num_units[1],\n",
    "                      'kernel_size': 1, 'stride': 1, 'bias': True}\n",
    "            self.conv2 = nn.Conv1d(**params)\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(nn.Linear(self.in_channels, self.num_units[0]), nn.ReLU())\n",
    "            self.conv2 = nn.Linear(self.num_units[0], self.num_units[1])\n",
    "        self.normalization = layer_normalization(self.in_channels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.conv:\n",
    "            inputs = inputs.permute(0, 2, 1)\n",
    "        outputs = self.conv1(inputs)\n",
    "        outputs = self.conv2(outputs)\n",
    "\n",
    "        # Residual connection\n",
    "        outputs += inputs\n",
    "\n",
    "        # Layer normalization\n",
    "        if self.conv:\n",
    "            outputs = self.normalization(outputs.permute(0, 2, 1))\n",
    "        else:\n",
    "            outputs = self.normalization(outputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "class ScriptWriter_cpre(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        eta=0.5,\n",
    "        max_sentence_len = 50,\n",
    "        max_num_utterance = 11,\n",
    "        embedding_file = 'data/embeddings_ko.pkl',\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.max_num_utterance = max_num_utterance\n",
    "        self.negative_samples = 1\n",
    "        self.max_sentence_len = max_sentence_len\n",
    "        self.emb_size = 200 # word_embedding_size \n",
    "        self.hidden_units = 200\n",
    "        #self.total_words = 43514\n",
    "        self.total_words = 11883\n",
    "        #self.batch_size = batch_size\n",
    "        #self.eval_batch_size = eval_batch_size\n",
    "        #self.learning_rate_ph = tf.compat.v1.placeholder(tf.float32, shape=[], name='learning_rate')\n",
    "        self.dropout_rate = 0\n",
    "        self.num_heads = 1\n",
    "        self.num_blocks = 3 \n",
    "        self.eta = eta\n",
    "        #self.gamma = tf.compat.v1.get_variable('gamma', shape=1, dtype=tf.float32, trainable=True, initializer=tf.constant_initializer(0.5))\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.5), requires_grad=True)\n",
    "        word_emb = pickle.load(open(embedding_file, 'rb'), encoding=\"bytes\")\n",
    "        word_emb = torch.FloatTensor(word_emb)\n",
    "        self.embedding = nn.Embedding.from_pretrained(word_emb, freeze=True)\n",
    "        \n",
    "        for i in range(self.num_blocks):\n",
    "            self.__setattr__('self_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('self_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "            \n",
    "        for i in range(self.num_blocks+1):\n",
    "            self.__setattr__('ru_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('ru_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "            self.__setattr__('ur_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('ur_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "            self.__setattr__('nu_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('nu_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "            self.__setattr__('un_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('un_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "            self.__setattr__('nr_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('nr_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "            self.__setattr__('rn_multihead_attention_%d' % i, multihead_attention(\n",
    "                     num_units=self.hidden_units,\n",
    "                     num_heads=self.num_heads,\n",
    "                     dropout_rate=self.dropout_rate,\n",
    "                     causality=False))\n",
    "            self.__setattr__('rn_feedforward_%d' % i, feedforward(\n",
    "                     self.hidden_units,\n",
    "                     [self.hidden_units, self.hidden_units]))\n",
    "                                       \n",
    "                                       \n",
    "        self.n_dense = nn.Linear(self.hidden_units, self.hidden_units)\n",
    "        self.lastu_dense = nn.Linear(self.max_sentence_len, 1) \n",
    "        self.lastur_dense = nn.Linear(self.max_sentence_len, 1)\n",
    "        \n",
    "        depth = self.max_num_utterance # 11\n",
    "        height = self.max_sentence_len # 50\n",
    "        width = self.max_sentence_len # 50\n",
    "        padding = ((depth%3 + 1)//2, (height%3 + 1)//2, (width%3 + 1)//2,)\n",
    "        conv3d_1_layer = nn.Conv3d((self.num_blocks+1)*2, 32, 3, padding='same') \n",
    "        nn.init.uniform_(conv3d_1_layer.weight, -0.01, 0.01) \n",
    "        self.conv3d_1 = torch.nn.Sequential(conv3d_1_layer, torch.nn.ELU())\n",
    "        self.maxpool3d_1 = torch.nn.MaxPool3d(3, padding=padding)\n",
    "        \n",
    "        depth = (self.max_num_utterance+2)//3 # 11\n",
    "        height = (self.max_sentence_len+2)//3 # 50\n",
    "        width = (self.max_sentence_len+2)//3 # 50\n",
    "        padding = ((depth%3 + 1)//2, (height%3 + 1)//2, (width%3 + 1)//2,)\n",
    "        conv3d_2_layer = nn.Conv3d(32, 32, 3, padding='same') \n",
    "        nn.init.uniform_(conv3d_2_layer.weight, -0.01, 0.01)\n",
    "        self.conv3d_2 = torch.nn.Sequential(conv3d_2_layer, torch.nn.ELU())\n",
    "        self.maxpool3d_2 = torch.nn.MaxPool3d(3, padding=padding)\n",
    "        mur_flatten_size = ((depth+2)//3)*((height+2)//3)*((width+2)//3)*32\n",
    "        #print('mur_flatten_size =', mur_flatten_size)\n",
    "        \n",
    "        height = self.max_sentence_len # 50\n",
    "        width = self.max_sentence_len # 50\n",
    "        padding = ((height%3 + 1)//2, (width%3 + 1)//2)\n",
    "        conv2d_1_layer = nn.Conv2d((self.num_blocks+1)*2, 32, 3, padding='same')\n",
    "        nn.init.uniform_(conv2d_1_layer.weight, -0.01, 0.01)\n",
    "        self.conv2d_1 = torch.nn.Sequential(conv2d_1_layer, torch.nn.ELU())\n",
    "        self.maxpool2d_1 = torch.nn.MaxPool2d(3, padding=padding)\n",
    "        \n",
    "        height = (self.max_sentence_len+2)//3 # 50\n",
    "        width = (self.max_sentence_len+2)//3 # 50\n",
    "        padding = ((height%3 + 1)//2, (width%3 + 1)//2)\n",
    "        conv2d_2_layer = nn.Conv2d(32, 32, 3, padding='same') \n",
    "        nn.init.uniform_(conv2d_2_layer.weight, -0.01, 0.01)\n",
    "        self.conv2d_2 = torch.nn.Sequential(conv2d_2_layer, torch.nn.ELU())\n",
    "        self.maxpool2d_2 = torch.nn.MaxPool2d(3, padding=padding)\n",
    "        \n",
    "        total_flatten_size = mur_flatten_size*2 + ((height+2)//3)*((width+2)//3)*32\n",
    "        #print('total_flatten_size =', total_flatten_size)\n",
    "        \n",
    "        self.logits_dense = nn.Linear(total_flatten_size, 1)  \n",
    "        nn.init.orthogonal_(self.logits_dense.weight)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        response: Optional[torch.Tensor] = None,\n",
    "        gt_response: Optional[torch.Tensor] = None,\n",
    "        narrative: Optional[torch.Tensor] = None,\n",
    "        utterance: Optional[torch.Tensor] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        print('response.shape =', response.shape)\n",
    "        print('response type =', type(response))\n",
    "        print('utterance.shape =', utterance.shape)\n",
    "        all_utterances = torch.unbind(utterance, dim=1)\n",
    "        #print(all_utterances[0].shape)\n",
    "        \n",
    "        response_embeddings = self.embedding(response)\n",
    "        Hr_stack = [response_embeddings]\n",
    "        for i in range(self.num_blocks):\n",
    "            response_embeddings = self.__getattr__('self_multihead_attention_%d' % i)(\n",
    "                response_embeddings, response_embeddings, response_embeddings)\n",
    "            response_embeddings = self.__getattr__('self_feedforward_%d' % i)(response_embeddings)\n",
    "            Hr_stack.append(response_embeddings)\n",
    "        \n",
    "        gt_response_embeddings = self.embedding(gt_response)\n",
    "        Hgtr_stack = [gt_response_embeddings]\n",
    "        for i in range(self.num_blocks):\n",
    "            gt_response_embeddings = self.__getattr__('self_multihead_attention_%d' % i)(\n",
    "                gt_response_embeddings, gt_response_embeddings, gt_response_embeddings)\n",
    "            gt_response_embeddings = self.__getattr__('self_feedforward_%d' % i)(gt_response_embeddings)\n",
    "            Hgtr_stack.append(response_embeddings)\n",
    "            \n",
    "        narrative_embeddings = self.embedding(narrative)\n",
    "        Hn_stack = [narrative_embeddings]\n",
    "        for i in range(self.num_blocks):\n",
    "            narrative_embeddings = self.__getattr__('self_multihead_attention_%d' % i)(\n",
    "                narrative_embeddings, narrative_embeddings, narrative_embeddings)\n",
    "            narrative_embeddings = self.__getattr__('self_feedforward_%d' % i)(narrative_embeddings)\n",
    "            Hn_stack.append(response_embeddings)\n",
    "        \n",
    "        Mur, Mun = [], []\n",
    "        self.decay_factor = []\n",
    "        last_u_reps = []\n",
    "        turn_id = 0\n",
    "        \n",
    "        for utterance in all_utterances:\n",
    "            utterance_embeddings = self.embedding(utterance)\n",
    "            Hu_stack = [utterance_embeddings]\n",
    "            for i in range(self.num_blocks):\n",
    "                utterance_embeddings = self.__getattr__('self_multihead_attention_%d' % i)(\n",
    "                    utterance_embeddings, utterance_embeddings, utterance_embeddings)\n",
    "                utterance_embeddings = self.__getattr__('self_feedforward_%d' % i)(utterance_embeddings)\n",
    "                Hu_stack.append(utterance_embeddings)\n",
    "                \n",
    "            if turn_id == self.max_num_utterance - 1:\n",
    "                last_u_reps = Hu_stack\n",
    "            \n",
    "            r_a_u_stack = []\n",
    "            u_a_r_stack = []\n",
    "            for i in range(self.num_blocks + 1):\n",
    "                r_a_u = self.__getattr__('ru_multihead_attention_%d' % i)(\n",
    "                    Hr_stack[i], Hu_stack[i], Hu_stack[i])\n",
    "                r_a_u = self.__getattr__('ru_feedforward_%d' % i)(r_a_u)\n",
    "                r_a_u_stack.append(r_a_u)\n",
    "                u_a_r = self.__getattr__('ur_multihead_attention_%d' % i)(\n",
    "                    Hu_stack[i], Hr_stack[i], Hr_stack[i])\n",
    "                u_a_r = self.__getattr__('ur_feedforward_%d' % i)(u_a_r)\n",
    "                u_a_r_stack.append(u_a_r)\n",
    "            r_a_u_stack.extend(Hr_stack)\n",
    "            u_a_r_stack.extend(Hu_stack)\n",
    "            \n",
    "            n_a_u_stack = []\n",
    "            u_a_n_stack = []\n",
    "            for i in range(self.num_blocks + 1):\n",
    "                n_a_u = self.__getattr__('nu_multihead_attention_%d' % i)(\n",
    "                    Hn_stack[i], Hu_stack[i], Hu_stack[i])\n",
    "                n_a_u = self.__getattr__('nu_feedforward_%d' % i)(n_a_u)\n",
    "                n_a_u_stack.append(n_a_u)\n",
    "                u_a_n = self.__getattr__('un_multihead_attention_%d' % i)(\n",
    "                    Hu_stack[i], Hn_stack[i], Hn_stack[i])\n",
    "                u_a_n = self.__getattr__('un_feedforward_%d' % i)(u_a_n)\n",
    "                u_a_n_stack.append(u_a_n)\n",
    "            n_a_u_stack.extend(Hn_stack)\n",
    "            u_a_n_stack.extend(Hu_stack)\n",
    "            \n",
    "            r_a_u = torch.stack(r_a_u_stack, dim=-1)\n",
    "            u_a_r = torch.stack(u_a_r_stack, dim=-1)\n",
    "            n_a_u = torch.stack(n_a_u_stack, dim=-1)\n",
    "            u_a_n = torch.stack(u_a_n_stack, dim=-1)\n",
    "            \n",
    "            # sim shape [batch, max_sent_len, max_sent_len, 2 * (stack_num + 1)]\n",
    "            # divide sqrt(200) to prevent gradient explosion\n",
    "            # (-1, 50, 50, 8)\n",
    "            sim_ur = torch.einsum('biks,bjks->bijs', u_a_r, r_a_u) / torch.sqrt(torch.tensor(200.0))  # for no rp and normal\n",
    "            sim_un = torch.einsum('biks,bjks->bijs', u_a_n, n_a_u) / torch.sqrt(torch.tensor(200.0))  # for no rp and normal\n",
    "            \n",
    "            self_n = torch.nn.functional.normalize(torch.stack(Hn_stack, dim=-1))  # for no rp\n",
    "            self_u = torch.nn.functional.normalize(torch.stack(Hu_stack, dim=-1))  # for no rp\n",
    "            Hn_stack_tensor = torch.stack(Hn_stack, dim=-1)  # [batch, o_len, embedding_size, stack]\n",
    "            \n",
    "            self_sim = torch.einsum('biks,bjks->bijs', self_u, self_n)  # [batch, u_len, o_len, stack]\n",
    "            self_sim = 1 - self.gamma * torch.sum(self_sim, dim=1)  # [batch, (1), o_len, stack]\n",
    "            Hn_stack = torch.einsum('bjkl,bjl->bjkl', Hn_stack_tensor, self_sim)\n",
    "            Hn_stack = torch.unbind(Hn_stack, dim=-1)\n",
    "            \n",
    "            Mur.append(sim_ur)\n",
    "            Mun.append(sim_un)\n",
    "            turn_id += 1\n",
    "            \n",
    "        # Hn_stack ( (-1,50,200), ... ) len = block_num\n",
    "        #print('narrative updated final len(Hn_stack) =', len(Hn_stack), ', Hn_stack[0].shape =', Hn_stack[0].shape)\n",
    "        \n",
    "        #print('stack shape = ', torch.stack(Hn_stack, dim=2).shape)\n",
    "        Hn_stack_for_tracking = self.n_dense(torch.stack(Hn_stack, dim=2))  # [batch, o_len, stack, embedding_size]\n",
    "        #print('Hn_stack_for_tracking.shape after dense =', Hn_stack_for_tracking.shape)\n",
    "        Hn_stack_for_tracking = Hn_stack_for_tracking.permute((0, 1, 3, 2))  # [batch, o_len, embedding_size, stack]\n",
    "        #print('Hn_stack_for_tracking.shape after permute =', Hn_stack_for_tracking.shape)\n",
    "        Hlastu_stack_for_tracking = torch.stack(last_u_reps, dim=-1)  # [batch, u_len, embedding_size, stack]\n",
    "        Hr_stack_for_tracking = torch.stack(Hgtr_stack, dim=-1)  # [batch, r_len, embedding_size, stack]\n",
    "        Hlastu = Hlastu_stack_for_tracking.permute((0, 2, 3, 1)) # [batch, embedding_size, stack, u_len]\n",
    "        Hlastu = torch.squeeze(self.lastu_dense(Hlastu), dim=-1)  # [batch, embedding_size, stack]\n",
    "        p1_tensor = nn.functional.softmax(torch.einsum('bnds,bds->bns', Hn_stack_for_tracking, Hlastu), dim=1)  # [batch, o_len, stack]\n",
    "        Hlastur = Hr_stack_for_tracking.permute((0, 2, 3, 1))\n",
    "        Hlastur = torch.squeeze(self.lastur_dense(Hlastur), dim=-1)  # [batch, embedding_size, stack]\n",
    "        p2_tensor = nn.functional.softmax(torch.einsum('bnds,bds->bns', Hn_stack_for_tracking, Hlastur), dim=1)  # [batch, o_len, stack]\n",
    "        p1 = torch.unbind(p1_tensor, dim=-1)\n",
    "        p2 = torch.unbind(p2_tensor, dim=-1)\n",
    "        #print('len(p1) =', len(p1), ', p1[0].shape =', p1[0].shape)\n",
    "        \n",
    "        n_a_r_stack = []\n",
    "        r_a_n_stack = []\n",
    "        for i in range(self.num_blocks + 1):\n",
    "            n_a_r = self.__getattr__('nr_multihead_attention_%d' % i)(\n",
    "                Hn_stack[i], Hr_stack[i], Hr_stack[i])\n",
    "            n_a_r = self.__getattr__('nr_feedforward_%d' % i)(n_a_r)\n",
    "            n_a_r_stack.append(n_a_r)\n",
    "            r_a_n = self.__getattr__('rn_multihead_attention_%d' % i)(\n",
    "                Hr_stack[i], Hn_stack[i], Hn_stack[i])\n",
    "            r_a_n = self.__getattr__('rn_feedforward_%d' % i)(r_a_n)\n",
    "            r_a_n_stack.append(r_a_n)\n",
    "        n_a_r_stack.extend(Hn_stack)\n",
    "        r_a_n_stack.extend(Hr_stack)\n",
    "\n",
    "        n_a_r = torch.stack(n_a_r_stack, dim=-1)\n",
    "        r_a_n = torch.stack(r_a_n_stack, dim=-1)\n",
    "\n",
    "        Mrn = torch.einsum('biks,bjks->bijs', n_a_r, r_a_n) / torch.sqrt(torch.tensor(200.0))\n",
    "        self.rosim = Mrn\n",
    "        Mur = torch.stack(Mur, dim=1)\n",
    "        Mun = torch.stack(Mun, dim=1)\n",
    "        \n",
    "        #print('Mur.shape =', Mur.shape)\n",
    "        #print('Mun.shape =', Mun.shape)\n",
    "        #print('Mrn.shape =', Mrn.shape)\n",
    "        \n",
    "        conv3d = self.conv3d_1(Mur.permute(0,4,1,2,3)) # (-1, 11, 50, 50, 8) -> (-1, 8, 11, 50, 50)\n",
    "        #print('conv3d.shape =', conv3d.shape)\n",
    "        pool3d = self.maxpool3d_1(conv3d)              # (-1, 32, 4, 17, 17)\n",
    "        #print('pool3d.shape =', pool3d.shape)\n",
    "        conv3d2 = self.conv3d_2(pool3d)\n",
    "        pool3d2 = self.maxpool3d_2(conv3d2)            # (-1, 32, 2, 6, 6)\n",
    "        #print('pool3d2.shape =', pool3d2.shape)\n",
    "        mur = torch.flatten(pool3d2.permute(0,2,3,4,1), start_dim=1)\n",
    "        #print('mur.shape =', mur.shape)\n",
    "        \n",
    "        conv3d = self.conv3d_1(Mun.permute(0,4,1,2,3))\n",
    "        pool3d = self.maxpool3d_1(conv3d)\n",
    "        conv3d2 = self.conv3d_2(pool3d)\n",
    "        pool3d2 = self.maxpool3d_2(conv3d2)\n",
    "        mun = torch.flatten(pool3d2.permute(0,2,3,4,1), start_dim=1)\n",
    "        #print('mun.shape =', mun.shape)\n",
    "        \n",
    "        conv2d = self.conv2d_1(Mrn.permute((0,3,1,2)))\n",
    "        pool2d = self.maxpool2d_1(conv2d)\n",
    "        conv2d2 = self.conv2d_2(pool2d)\n",
    "        pool2d2 = self.maxpool2d_2(conv2d2)\n",
    "        mrn = torch.flatten(pool2d2.permute(0,2,3,1), start_dim=1) \n",
    "        #print('mrn.shape =', mrn.shape)\n",
    "        \n",
    "        all_vector = torch.cat([mur, mun, mrn], dim=-1)\n",
    "        #print('all_vector.shape =', all_vector.shape)\n",
    "        logits = torch.reshape(self.logits_dense(all_vector), shape=(-1,))\n",
    "        y_pred = torch.sigmoid(logits)\n",
    "        #print('y_pred.shape =', y_pred.shape)\n",
    "        \n",
    "        return {\n",
    "            'y_pred': y_pred,\n",
    "            'logits': logits,\n",
    "            'p1': p1,\n",
    "            'p2': p2\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00109cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response.shape = torch.Size([4, 50])\n",
      "response type = <class 'torch.Tensor'>\n",
      "utterance.shape = torch.Size([4, 11, 50])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "Q shape: torch.Size([4, 50, 200])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "N = 4\n",
    "device = torch.device(\"cuda\")\n",
    "response = torch.from_numpy(np.random.randint(1, 11400, size=(N, 50))).to(device)\n",
    "gt_response = torch.from_numpy(np.random.randint(1, 11400, size=(N, 50))).to(device)\n",
    "narrative = torch.from_numpy(np.random.randint(1, 11400, size=(N, 50))).to(device)\n",
    "utterance = torch.from_numpy(np.random.randint(1, 11400, size=(N, 11, 50))).to(device)\n",
    "\n",
    "model = ScriptWriter_cpre().to(device)\n",
    "\n",
    "_ = model(response=response, gt_response=gt_response, narrative=narrative, utterance=utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023f562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0511,  0.5404, -0.8509,  0.4603, -1.9017,  1.5315, -0.0478, -1.3589,\n",
       "          0.5049,  0.8584, -0.4572, -0.0399, -0.8955, -0.9557, -0.9209, -1.0791,\n",
       "          2.2756, -0.3729,  0.5335,  1.4092, -0.1845, -0.8261, -0.9601,  1.4598,\n",
       "         -0.4093,  0.6887,  0.1956,  0.3117, -0.0178, -0.6985]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding(torch.tensor([3]).to(device))[:, 0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall numpy -y\n",
    "#!pip install datasets\n",
    "\n",
    "!pip install numpy==1.19.5\n",
    "!pip install pandas==1.4.0\n",
    "!pip install datasets==1.18.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14888f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "class ScriptwriterTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.bcewithlogitsloss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        y_true = inputs.pop('labels')\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.pop('logits')\n",
    "        p1 = outputs.pop('p1')\n",
    "        p2 = outputs.pop('p2')\n",
    "        \n",
    "        KL_loss = 0.0\n",
    "        for i in range(model.num_blocks + 1):\n",
    "            KL_loss += torch.mean(nn.functional.kl_div(p1[i], p2[i]))\n",
    "        KL_loss /= (model.num_blocks + 1)\n",
    "        RS_loss = torch.mean(torch.clip(self.bcewithlogitsloss(labels=y_true, logits=logits), -10, 10))\n",
    "        loss = model.eta * RS_loss + (1 - model.eta) * KL_loss\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9635f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset story_data (/home/kotech/.cache/huggingface/datasets/story_data/original/1.0.0/ec7f2c2a5c010e3fa36891e870388b66436f5a5edd79bce7b1ec2f4808991faa)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec29f74c368e4840a34fd08476d1b57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset('story_data', 'original')\n",
    "\n",
    "model_checkpoint = \"script-writer-cpre\"\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_checkpoint}-dev\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf48594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5526cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ScriptWriter_cpre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffeb69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ScriptwriterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4d3f2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `ScriptWriter_cpre.forward` and have been ignored: id. If id are not expected by `ScriptWriter_cpre.forward`,  you can safely ignore this message.\n",
      "/home/kotech/venv-torch1102/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 136524\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 51198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response.shape =response.shape = torch.Size([4, 50])\n",
      "response type = <class 'torch.Tensor'>\n",
      "utterance.shape = torch.Size([4, 11, 50])\n",
      " torch.Size([4, 50])\n",
      "response type = <class 'torch.Tensor'>\n",
      "utterance.shape = torch.Size([4, 11, 50])\n",
      "q shape: torch.Size([4, 50, 200])\n",
      "q shape: torch.Size([4, 50, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [3,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:699: indexSelectLargeIndex: block: [4,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_31870/125454331.py\", line 316, in forward\n    response_embeddings = self.__getattr__('self_multihead_attention_%d' % i)(\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_31870/125454331.py\", line 57, in forward\n    Q = self.Q_proj(queries)  # (N, T_q, C)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 141, in forward\n    input = module(input)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\nRuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/transformers/trainer.py:1521\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1518\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1520\u001b[0m )\n\u001b[0;32m-> 1521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/transformers/trainer.py:1763\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1761\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1763\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1766\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1769\u001b[0m ):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/transformers/trainer.py:2499\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2499\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2502\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "Cell \u001b[0;32mIn [2], line 11\u001b[0m, in \u001b[0;36mScriptwriterTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      9\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     p1 \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/venv-torch1102/lib/python3.9/site-packages/torch/_utils.py:434\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_31870/125454331.py\", line 316, in forward\n    response_embeddings = self.__getattr__('self_multihead_attention_%d' % i)(\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_31870/125454331.py\", line 57, in forward\n    Q = self.Q_proj(queries)  # (N, T_q, C)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 141, in forward\n    input = module(input)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n    return F.linear(input, self.weight, self.bias)\n  File \"/home/kotech/venv-torch1102/lib/python3.9/site-packages/torch/nn/functional.py\", line 1848, in linear\n    return torch._C._nn.linear(input, weight, bias)\nRuntimeError: CUDA error: CUBLAS_STATUS_INTERNAL_ERROR when calling `cublasCreate(handle)`\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc8f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
